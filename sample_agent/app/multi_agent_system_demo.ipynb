{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Multi-Agent System Demo with LangGraph\n",
        "\n",
        "This notebook demonstrates a sophisticated multi-agent system using LangGraph's Swarm architecture. The system includes:\n",
        "- **Main Agent**: Coordination and task orchestration\n",
        "- **Alice**: Math calculations specialist\n",
        "- **Bob**: Weather specialist with pirate personality\n",
        "\n",
        "## Features\n",
        "- Memory checkpointer for state inspection\n",
        "- Tool integration with interrupts\n",
        "- Agent handoff capabilities\n",
        "- Real-time state tracking\n",
        "\n",
        "\n",
        "## Example Scenario\n",
        "We'll implement the Portuguese example: \"Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo numero que eu estou pensando e me retorne o final.\"\n",
        "(What's the current temperature in Campeche? Now take that temperature and multiply it by the number I'm thinking of and return the result.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Imports and Configuration\n",
        "\n",
        "First, we'll import all necessary libraries and set up our language models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports for type checking and agents\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from typing import Annotated\n",
        "import operator\n",
        "import os\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, AIMessage, ToolMessage, HumanMessage, BaseMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain.tools import tool\n",
        "from langchain_core.tools import tool, InjectedToolCallId, BaseTool\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.types import Command, interrupt\n",
        "from langgraph.graph import StateGraph, MessagesState\n",
        "from langgraph.constants import START, END\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState, AgentStateWithStructuredResponse\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# LangGraph Swarm imports\n",
        "from langgraph_swarm import (\n",
        "    create_handoff_tool,\n",
        "    create_swarm,\n",
        "    SwarmState,\n",
        "    add_active_agent_router,\n",
        ")\n",
        "\n",
        "# Pydantic for data models\n",
        "from pydantic import BaseModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports loaded successfully!\n",
            "ü§ñ Model initialized: client=<openai.resources.chat.completions.completions.Completions object at 0x10f819c70> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f81bb00> root_client=<openai.OpenAI object at 0x10f819970> root_async_client=<openai.AsyncOpenAI object at 0x10f819280> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
          ]
        }
      ],
      "source": [
        "# Initialize language models\n",
        "model = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n",
        "model_groq = model\n",
        "\n",
        "print(\"‚úÖ All imports loaded successfully!\")\n",
        "print(f\"ü§ñ Model initialized: {model}\")\n",
        "\n",
        "MAIN_AGENT_PROMPT = \"\"\"You are the Main Coordination Agent responsible for task orchestration and completion.\n",
        "\n",
        "CORE RESPONSIBILITIES:\n",
        "1. Analyze incoming tasks and develop a strategic execution plan\n",
        "2. Gather necessary information from users when requirements are unclear\n",
        "3. Delegate specialized tasks to appropriate expert agents\n",
        "4. Coordinate between agents to ensure seamless task completion\n",
        "\n",
        "WORKFLOW PROCESS:\n",
        "1. ANALYZE: Break down the user's request and identify required expertise\n",
        "2. PLAN: Structure a clear strategy outlining steps and agent assignments\n",
        "3. GATHER: Use `ask_user` tool to collect missing information before proceeding\n",
        "4. DELEGATE: Hand off specific, well-defined subtasks to specialized agents\n",
        "5. COORDINATE: Monitor progress and facilitate inter-agent communication\n",
        "\n",
        "HANDOFF PROTOCOL:\n",
        "- Always provide clear, specific instructions when transferring tasks\n",
        "- Include relevant context and expected deliverables\n",
        "- Ensure each agent receives the exact information needed for their specialization\n",
        "\n",
        "Remember: Strategic planning before action ensures optimal task completion.\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Tool Definitions\n",
        "\n",
        "We define three core tools for our multi-agent system:\n",
        "- **get_weather**: Retrieves weather information for a location\n",
        "- **calculate_math**: Performs mathematical calculations\n",
        "- **ask_user**: Enables human-in-the-loop interactions with interrupts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tool definitions completed!\n",
            "üîß Available tools: get_weather, calculate_math, ask_user\n"
          ]
        }
      ],
      "source": [
        "def get_weather(location: str, tool_call_id: Annotated[str, InjectedToolCallId]):\n",
        "    \"\"\"\n",
        "    Get the weather for a given location.\n",
        "    Returns temperature data and updates the system state.\n",
        "    \"\"\"\n",
        "    print(f\"üå§Ô∏è Getting weather for {location}\")\n",
        "    import random\n",
        "\n",
        "    temperature = random.randint(20, 30)\n",
        "\n",
        "    return Command(\n",
        "        update={\n",
        "            \"location\": location,\n",
        "            \"temperature\": f\"{temperature} degrees\",  # Simulated temperature for Campeche\n",
        "            \"date\": f\"2025-01-{temperature}\",\n",
        "            \"time\": f\"12:{temperature}:00\",\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "            \"messages\": [\n",
        "                ToolMessage(\n",
        "                    f\"The weather for {location} is {temperature} degrees.\",\n",
        "                    tool_call_id=tool_call_id,\n",
        "                )\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def calculate_math(expression: str, tool_call_id: Annotated[str, InjectedToolCallId]):\n",
        "    \"\"\"\n",
        "    Calculate a simple math expression.\n",
        "    Supports: addition (+), multiplication (*), subtraction (-), division (/)\n",
        "    Example: \"2 + 3\" or \"70 * 3\"\n",
        "    \"\"\"\n",
        "    print(f\"üî¢ Calculating math for {expression}\")\n",
        "\n",
        "    try:\n",
        "        if \"+\" in expression:\n",
        "            parts = expression.split(\"+\")\n",
        "            result = sum(float(part.strip()) for part in parts)\n",
        "        elif \"*\" in expression:\n",
        "            parts = expression.split(\"*\")\n",
        "            result = 1\n",
        "            for part in parts:\n",
        "                result *= float(part.strip())\n",
        "        elif \"-\" in expression:\n",
        "            parts = expression.split(\"-\")\n",
        "            result = float(parts[0].strip()) - float(parts[1].strip())\n",
        "        elif \"/\" in expression:\n",
        "            parts = expression.split(\"/\")\n",
        "            result = float(parts[0].strip()) / float(parts[1].strip())\n",
        "        else:\n",
        "            result = float(expression.strip())\n",
        "\n",
        "        return Command(\n",
        "            update={\n",
        "                \"math_expression\": expression,\n",
        "                \"math_result\": result,\n",
        "                \"messages\": [\n",
        "                    ToolMessage(\n",
        "                        f\"The result of {expression} is {result}\",\n",
        "                        tool_call_id=tool_call_id,\n",
        "                    )\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Could not calculate {expression}. Please use format like '2 + 3' or '10 * 5'\"\n",
        "        print(f\"‚ùå Math error: {e}\")\n",
        "        return Command(\n",
        "            update={\n",
        "                \"messages\": [ToolMessage(error_msg, tool_call_id=tool_call_id)],\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "def ask_user(question_to_user: str, tool_call_id: Annotated[str, InjectedToolCallId]):\n",
        "    \"\"\"\n",
        "    This tool is used to ask the user any question.\n",
        "    It's important to always ask for things to make sure you're using the right information.\n",
        "    Uses interrupt mechanism for human-in-the-loop interaction.\n",
        "    \"\"\"\n",
        "    print(f\"‚ùì Asking user: {question_to_user}\")\n",
        "\n",
        "    user_response = interrupt(\n",
        "        {\n",
        "            \"type\": \"question\",\n",
        "            \"question\": question_to_user,\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"üë§ User response: {user_response}\")\n",
        "    return f\"The user answered with: {user_response}\"\n",
        "\n",
        "\n",
        "print(\"‚úÖ Tool definitions completed!\")\n",
        "print(\"üîß Available tools: get_weather, calculate_math, ask_user\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. State Definitions and Workflow Compilation\n",
        "\n",
        "We define the state schemas that will track information across agent interactions, including temperature, location, math expressions, and results. The memory checkpointer enables state inspection and recovery.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Workflow compilation functions ready!\n",
            "üíæ Memory checkpointer will be used for state tracking\n"
          ]
        }
      ],
      "source": [
        "def compile_workflow(workflow: StateGraph):\n",
        "    \"\"\"\n",
        "    Compile the workflow with memory checkpointer for state inspection.\n",
        "    Enables state recovery and debugging capabilities.\n",
        "    \"\"\"\n",
        "    is_langgraph_api = (\n",
        "        os.environ.get(\"LANGGRAPH_API\", \"false\").lower() == \"true\"\n",
        "        or os.environ.get(\"LANGGRAPH_API_DIR\") is not None\n",
        "    )\n",
        "\n",
        "    if is_langgraph_api:\n",
        "        print(\"üåê Compiling for LangGraph API\")\n",
        "        return workflow.compile()\n",
        "    else:\n",
        "        print(\"üíæ Compiling with Memory Checkpointer\")\n",
        "        memory = MemorySaver()\n",
        "        return workflow.compile(checkpointer=memory)\n",
        "\n",
        "\n",
        "# Hook functions for debugging and monitoring\n",
        "def pre_hook_supervisor_node(state, config: RunnableConfig):\n",
        "    \"\"\"Pre-execution hook for debugging\"\"\"\n",
        "    print(f\"üîç Pre-hook supervisor: {state}\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def post_hook_supervisor_node(state, config: RunnableConfig):\n",
        "    \"\"\"Post-execution hook for debugging\"\"\"\n",
        "    print(f\"‚úÖ Post-hook supervisor: {state}\")\n",
        "    return state\n",
        "\n",
        "print(\"‚úÖ Workflow compilation functions ready!\")\n",
        "print(\"üíæ Memory checkpointer will be used for state tracking\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Multi-Agent System Creation\n",
        "\n",
        "This section creates the complete multi-agent system with:\n",
        "- **Main Agent**: Coordinates tasks and manages workflow\n",
        "- **Alice**: Mathematics specialist \n",
        "- **Bob**: Weather specialist with pirate personality\n",
        "\n",
        "Each agent has specific tools and capabilities, with handoff mechanisms for seamless collaboration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Initializing Multi-Agent System...\n",
            "ü§ñ Creating Main Agent...\n",
            "üî¢ Creating Alice (Math Specialist)...\n",
            "üå§Ô∏è Creating Bob (Weather Specialist)...\n",
            "üï∏Ô∏è Building workflow graph...\n",
            "üîß Compiling workflow...\n",
            "üíæ Compiling with Memory Checkpointer\n",
            "‚úÖ Multi-agent system created successfully!\n",
            "üéØ Agents: Main Agent, Alice (Math), Bob (Weather)\n",
            "üíæ Memory checkpointer enabled for state inspection\n",
            "üéâ System ready for execution!\n"
          ]
        }
      ],
      "source": [
        "from sample_agent.utils import create_handoff_tool_with_state_propagation\n",
        "\n",
        "def strip_tool_messages_node(state: dict) -> Command:\n",
        "    return Command(update={\n",
        "        \"messages\": [\n",
        "            m for m in state[\"messages\"]\n",
        "            if m.__class__.__name__ != \"ToolMessage\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "\n",
        "def create_multi_agent_system_swarm_mode():\n",
        "    \"\"\"Create the multi-agent system with supervisor\"\"\"\n",
        "\n",
        "    # State definitions for tracking data across agents\n",
        "    class FullState(AgentState):\n",
        "        temperature: float\n",
        "        location: str\n",
        "        weather: str\n",
        "        math_expression: str\n",
        "        math_result: str\n",
        "\n",
        "    class AliceState(AgentStateWithStructuredResponse):\n",
        "        math_expression: str\n",
        "        math_result: str\n",
        "\n",
        "    class AliceOutput(BaseModel):\n",
        "        math_expression: str\n",
        "        math_result: str\n",
        "\n",
        "    class BobState(AgentStateWithStructuredResponse):\n",
        "        location: str\n",
        "        weather: str\n",
        "        temperature: float\n",
        "\n",
        "    class BobOutput(BaseModel):\n",
        "        location: str\n",
        "        weather: str\n",
        "        temperature: float\n",
        "\n",
        "    # Create Main Agent - Coordination and Planning\n",
        "    print(\"ü§ñ Creating Main Agent...\")\n",
        "    main_agent_model = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n",
        "    main_agent_tools = [\n",
        "        ask_user,\n",
        "        create_handoff_tool(\n",
        "            agent_name=\"Alice\",\n",
        "            description=\"Transfer to Alice, she can help with any math\",\n",
        "        ),\n",
        "        create_handoff_tool(\n",
        "            agent_name=\"Bob\", \n",
        "            description=\"Transfer to Bob, he can help with weather\"\n",
        "        ),\n",
        "    ]\n",
        "    main_agent_model_bind_tools = main_agent_model.bind_tools(\n",
        "        main_agent_tools,\n",
        "        parallel_tool_calls=False,\n",
        "    )\n",
        "\n",
        "    main_agent = create_react_agent(\n",
        "        main_agent_model_bind_tools,\n",
        "        main_agent_tools,\n",
        "        prompt=MAIN_AGENT_PROMPT,\n",
        "        name=\"main_agent\",\n",
        "        state_schema=FullState,\n",
        "    )\n",
        "\n",
        "    # Create Alice - Math Specialist\n",
        "    print(\"üî¢ Creating Alice (Math Specialist)...\")\n",
        "    alice_model = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n",
        "    alice_tools = [\n",
        "        calculate_math,\n",
        "        create_handoff_tool(\n",
        "            agent_name=\"Bob\", \n",
        "            description=\"Transfer to Bob, he can help with weather\"\n",
        "        ),\n",
        "        create_handoff_tool(\n",
        "            agent_name=\"main_agent\",\n",
        "            description=\"Use this tool to send or ask the user for information to complete the task.\",\n",
        "        ),\n",
        "    ]\n",
        "    alice_model_bind_tools = alice_model.bind_tools(\n",
        "        alice_tools,\n",
        "        parallel_tool_calls=False,\n",
        "    )\n",
        "\n",
        "    alice = create_react_agent(\n",
        "        alice_model_bind_tools,\n",
        "        alice_tools,\n",
        "        prompt=\"You are Alice, a calculator expert. You are given a math expression and you need to calculate the result. If you need to ask the user for information, handoff to the main_agent.\",\n",
        "        name=\"Alice\",\n",
        "        state_schema=AliceState,\n",
        "        response_format=AliceOutput\n",
        "    )\n",
        "\n",
        "    # Create Bob - Weather Specialist\n",
        "    print(\"üå§Ô∏è Creating Bob (Weather Specialist)...\")\n",
        "    bob_model = init_chat_model(\"openai:gpt-4o-mini\", temperature=0)\n",
        "    bob_tools = [\n",
        "        ask_user,\n",
        "        get_weather,\n",
        "        create_handoff_tool_with_state_propagation(\n",
        "            agent_name=\"Alice\",\n",
        "            description=\"Transfer to Alice, she can help with any math or any calculation\",\n",
        "            propagate_keys=[\"location\", \"weather\", \"temperature\"],\n",
        "        ),\n",
        "        create_handoff_tool(\n",
        "            agent_name=\"main_agent\",\n",
        "            description=\"Use this tool to send or ask the user for information to complete the task.\",\n",
        "        ),\n",
        "    ]\n",
        "    bob_model_bind_tools = bob_model.bind_tools(\n",
        "        bob_tools,\n",
        "        parallel_tool_calls=False,\n",
        "    )\n",
        "\n",
        "    bob = create_react_agent(\n",
        "        bob_model_bind_tools,\n",
        "        bob_tools,\n",
        "        prompt=\"You are Bob, you speak like a pirate and you are a weather specialist. You are given a location and you need to return the weather for that location using the `get_weather` tool. If you need any user information, handoff back to the main_agent. To get the number that the user is thinking handoff back to the main_agent.\",\n",
        "        name=\"Bob\",\n",
        "        state_schema=BobState,\n",
        "        response_format=BobOutput,\n",
        "    )\n",
        "\n",
        "    # Create Swarm State that combines SwarmState with our custom state\n",
        "    class FullSwarmState(SwarmState, FullState):\n",
        "        temperature: float\n",
        "        location: str\n",
        "        weather: str\n",
        "        math_expression: str\n",
        "        math_result: str\n",
        "\n",
        "    # Build the workflow graph\n",
        "    print(\"üï∏Ô∏è Building workflow graph...\")\n",
        "    workflow = (\n",
        "        StateGraph(FullSwarmState)\n",
        "        .add_node(\n",
        "            main_agent,\n",
        "            destinations=(\n",
        "                \"Alice\",\n",
        "                \"Bob\",\n",
        "            ),\n",
        "        )\n",
        "        .add_node(alice, destinations=(\"main_agent\", \"Bob\"))\n",
        "        .add_node(bob, destinations=(\"main_agent\", \"Alice\"))\n",
        "        \n",
        "    )\n",
        "    workflow = workflow.add_node(\"cleanup_messages\", strip_tool_messages_node)\n",
        "    workflow = workflow.add_edge(\"main_agent\", \"cleanup_messages\")\n",
        "    workflow = workflow.add_edge(\"Alice\", \"cleanup_messages\")\n",
        "    workflow = workflow.add_edge(\"Bob\", \"cleanup_messages\")\n",
        "    workflow = workflow.add_edge(\"cleanup_messages\", END)\n",
        "    \n",
        "    # Add the router that enables tracking of the last active agent\n",
        "    workflow = add_active_agent_router(\n",
        "        builder=workflow,\n",
        "        route_to=[\"main_agent\", \"Alice\", \"Bob\"],\n",
        "        default_active_agent=\"main_agent\",\n",
        "    )\n",
        "\n",
        "    # Compile the workflow with memory checkpointer\n",
        "    print(\"üîß Compiling workflow...\")\n",
        "    graph = compile_workflow(workflow)\n",
        "    \n",
        "    print(\"‚úÖ Multi-agent system created successfully!\")\n",
        "    print(\"üéØ Agents: Main Agent, Alice (Math), Bob (Weather)\")\n",
        "    print(\"üíæ Memory checkpointer enabled for state inspection\")\n",
        "    \n",
        "    return graph\n",
        "\n",
        "\n",
        "# Create the multi-agent system\n",
        "print(\"üöÄ Initializing Multi-Agent System...\")\n",
        "graph = create_multi_agent_system_swarm_mode()\n",
        "print(\"üéâ System ready for execution!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Example Execution\n",
        "\n",
        "Now we'll run the specific example\n",
        "\n",
        "This demonstrates:\n",
        "1. Weather query delegation to Bob\n",
        "2. User interaction for the mystery number\n",
        "3. Math calculation by Alice\n",
        "4. Complete state tracking through memory checkpointer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Execution and analysis functions ready!\n"
          ]
        }
      ],
      "source": [
        "# Execution and State Inspection Functions\n",
        "\n",
        "def execute_campeche_example(query, thread_id):\n",
        "\n",
        "    # Create a unique thread for this execution\n",
        "    thread_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    \n",
        "    print(\"üáßüá∑ Starting Example...\")\n",
        "    print(f\"üìù Query: '{query}'\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Initial message\n",
        "    messages = [\n",
        "        HumanMessage(content=query)\n",
        "    ]\n",
        "    \n",
        "    # Step-by-step execution with state tracking\n",
        "    step_count = 0\n",
        "    max_steps = 10  # Prevent infinite loops\n",
        "    \n",
        "    try:\n",
        "        for step in graph.stream(\n",
        "            {\"messages\": messages}, \n",
        "            thread_config, \n",
        "            stream_mode=\"values\"\n",
        "        ):\n",
        "            step_count += 1\n",
        "            if step_count > max_steps:\n",
        "                print(f\"‚ö†Ô∏è Maximum steps ({max_steps}) reached. Stopping execution.\")\n",
        "                break\n",
        "                \n",
        "            print(f\"\\nüìç Step {step_count}:\")\n",
        "            \n",
        "            # Show current state\n",
        "            if hasattr(step, 'get'):\n",
        "                current_agent = step.get('active_agent', 'Unknown')\n",
        "                location = step.get('location', 'Not set')\n",
        "                temperature = step.get('temperature', 'Not set')\n",
        "                math_expression = step.get('math_expression', 'Not set')\n",
        "                math_result = step.get('math_result', 'Not set')\n",
        "                \n",
        "                print(f\"ü§ñ Active Agent: {current_agent}\")\n",
        "                print(f\"üìç Location: {location}\")\n",
        "                print(f\"üå°Ô∏è Temperature: {temperature}\")\n",
        "                print(f\"üî¢ Math Expression: {math_expression}\")\n",
        "                print(f\"üéØ Math Result: {math_result}\")\n",
        "            \n",
        "            # Show latest message\n",
        "            if 'messages' in step and step['messages']:\n",
        "                latest_message = step['messages'][-1]\n",
        "                print(f\"üí¨ Latest Message: {latest_message.content[:100]}...\")\n",
        "            \n",
        "            print(\"-\" * 40)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Execution error: {e}\")\n",
        "        print(\"üîß This is expected if interrupts are triggered for user input\")\n",
        "    \n",
        "    return thread_config\n",
        "\n",
        "\n",
        "def inspect_state(thread_config):\n",
        "    \"\"\"Inspect the current state using the memory checkpointer\"\"\"\n",
        "    \n",
        "    print(\"\\nüîç STATE INSPECTION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Get the current state from checkpointer\n",
        "        current_state = graph.get_state(thread_config)\n",
        "        \n",
        "        if current_state:\n",
        "            print(\"üìä Current State Values:\")\n",
        "            values = current_state.values\n",
        "            \n",
        "            for key, value in values.items():\n",
        "                if key == 'messages':\n",
        "                    print(f\"  üí¨ {key}: {len(value)} messages\")\n",
        "                    # Show last 2 messages\n",
        "                    for i, msg in enumerate(value[-2:], start=len(value)-1):\n",
        "                        msg_type = type(msg).__name__\n",
        "                        content = str(msg.content)[:80] + \"...\" if len(str(msg.content)) > 80 else str(msg.content)\n",
        "                        print(f\"    [{i}] {msg_type}: {content}\")\n",
        "                else:\n",
        "                    print(f\"  üéØ {key}: {value}\")\n",
        "            \n",
        "            print(f\"\\nüìç Next Steps: {current_state.next}\")\n",
        "            print(f\"üÜî State ID: {current_state.config.get('configurable', {}).get('thread_id', 'Unknown')}\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå No state found\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå State inspection error: {e}\")\n",
        "\n",
        "\n",
        "def simulate_user_input(thread_config, user_response=\"3\"):\n",
        "    \"\"\"Simulate user input to continue execution\"\"\"\n",
        "    \n",
        "    print(f\"\\nüë§ Simulating user input: '{user_response}'\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Continue execution with user input\n",
        "        for step in graph.stream(\n",
        "            None,  # No new input, just continue\n",
        "            thread_config,\n",
        "            stream_mode=\"values\"\n",
        "        ):\n",
        "            print(\"üìç Continuing execution after user input...\")\n",
        "            \n",
        "            # Show current state\n",
        "            if hasattr(step, 'get'):\n",
        "                current_agent = step.get('active_agent', 'Unknown')\n",
        "                location = step.get('location', 'Not set')\n",
        "                temperature = step.get('temperature', 'Not set')\n",
        "                math_expression = step.get('math_expression', 'Not set')\n",
        "                math_result = step.get('math_result', 'Not set')\n",
        "                \n",
        "                print(f\"ü§ñ Active Agent: {current_agent}\")\n",
        "                print(f\"üìç Location: {location}\")\n",
        "                print(f\"üå°Ô∏è Temperature: {temperature}\")\n",
        "                print(f\"üî¢ Math Expression: {math_expression}\")\n",
        "                print(f\"üéØ Math Result: {math_result}\")\n",
        "            \n",
        "            break  # Only show first step\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Continuation error: {e}\")\n",
        "\n",
        "\n",
        "def analyze_final_results(thread_config):\n",
        "    \"\"\"Analyze the final results of the Campeche example\"\"\"\n",
        "    \n",
        "    print(\"\\nüéØ FINAL ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        final_state = graph.get_state(thread_config)\n",
        "        \n",
        "        if final_state and final_state.values:\n",
        "            values = final_state.values\n",
        "            \n",
        "            location = values.get('location', 'Unknown')\n",
        "            temperature = values.get('temperature', 'Unknown')\n",
        "            math_expression = values.get('math_expression', 'Unknown')\n",
        "            math_result = values.get('math_result', 'Unknown')\n",
        "            \n",
        "            print(f\"üìç Location Queried: {location}\")\n",
        "            print(f\"üå°Ô∏è Temperature Retrieved: {temperature}\")\n",
        "            print(f\"üî¢ Math Expression Calculated: {math_expression}\")\n",
        "            print(f\"üéØ Final Result: {math_result}\")\n",
        "            \n",
        "            # Show final messages\n",
        "            messages = values.get('messages', [])\n",
        "            if messages:\n",
        "                print(f\"\\nüí¨ Total Messages Exchanged: {len(messages)}\")\n",
        "                print(\"\\nüìú Message History (last 3):\")\n",
        "                for i, msg in enumerate(messages[-3:], start=len(messages)-2):\n",
        "                    msg_type = type(msg).__name__\n",
        "                    content = str(msg.content)[:100] + \"...\" if len(str(msg.content)) > 100 else str(msg.content)\n",
        "                    print(f\"  [{i}] {msg_type}: {content}\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå No final state available\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Analysis error: {e}\")\n",
        "\n",
        "print(\"‚úÖ Execution and analysis functions ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Run the Demo\n",
        "\n",
        "Execute the example and observe the multi-agent collaboration in real-time. The system will:\n",
        "\n",
        "1. **Main Agent**: Analyze the complex request\n",
        "2. **Bob**: Get weather for Campeche (returns 70¬∞)\n",
        "3. **Main Agent**: Ask user for the mystery number\n",
        "4. **Alice**: Calculate 70 √ó user_number\n",
        "5. **Final Result**: Display the complete calculation\n",
        "\n",
        "**Note**: The execution may pause for user input simulation. This demonstrates the interrupt mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üáßüá∑ Starting Example...\n",
            "üìù Query: 'Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo dobro da temperatura e me retorne o final.'\n",
            "================================================================================\n",
            "\n",
            "üìç Step 1:\n",
            "ü§ñ Active Agent: Unknown\n",
            "üìç Location: Not set\n",
            "üå°Ô∏è Temperature: Not set\n",
            "üî¢ Math Expression: Not set\n",
            "üéØ Math Result: Not set\n",
            "üí¨ Latest Message: Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo dobro da tempe...\n",
            "----------------------------------------\n",
            "\n",
            "üìç Step 2:\n",
            "ü§ñ Active Agent: Bob\n",
            "üìç Location: Not set\n",
            "üå°Ô∏è Temperature: Not set\n",
            "üî¢ Math Expression: Not set\n",
            "üéØ Math Result: Not set\n",
            "üí¨ Latest Message: Successfully transferred to Bob...\n",
            "----------------------------------------\n",
            "üå§Ô∏è Getting weather for Campeche\n",
            "\n",
            "üìç Step 3:\n",
            "ü§ñ Active Agent: Alice\n",
            "üìç Location: Campeche\n",
            "üå°Ô∏è Temperature: 26 degrees\n",
            "üî¢ Math Expression: Not set\n",
            "üéØ Math Result: Not set\n",
            "üí¨ Latest Message: Successfully transferred to Alice...\n",
            "----------------------------------------\n",
            "üî¢ Calculating math for 26 * (2 * 26)\n",
            "‚ùå Math error: could not convert string to float: '(2'\n",
            "üî¢ Calculating math for 26 * 52\n",
            "\n",
            "üìç Step 4:\n",
            "ü§ñ Active Agent: Alice\n",
            "üìç Location: Campeche\n",
            "üå°Ô∏è Temperature: 26 degrees\n",
            "üî¢ Math Expression: 26 * 52\n",
            "üéØ Math Result: 1352.0\n",
            "üí¨ Latest Message: O resultado da multiplica√ß√£o da temperatura atual em Campeche (26 graus) pelo dobro da temperatura √©...\n",
            "----------------------------------------\n",
            "\n",
            "üìç Step 5:\n",
            "ü§ñ Active Agent: Alice\n",
            "üìç Location: Campeche\n",
            "üå°Ô∏è Temperature: 26 degrees\n",
            "üî¢ Math Expression: 26 * 52\n",
            "üéØ Math Result: 1352.0\n",
            "üí¨ Latest Message: O resultado da multiplica√ß√£o da temperatura atual em Campeche (26 graus) pelo dobro da temperatura √©...\n",
            "----------------------------------------\n",
            "\n",
            "üîç STATE INSPECTION\n",
            "==================================================\n",
            "üìä Current State Values:\n",
            "  üí¨ messages: 12 messages\n",
            "    [11] ToolMessage: The result of 26 * 52 is 1352.0\n",
            "    [12] AIMessage: O resultado da multiplica√ß√£o da temperatura atual em Campeche (26 graus) pelo do...\n",
            "  üéØ active_agent: Alice\n",
            "  üéØ temperature: 26 degrees\n",
            "  üéØ location: Campeche\n",
            "  üéØ math_expression: 26 * 52\n",
            "  üéØ math_result: 1352.0\n",
            "\n",
            "üìç Next Steps: ()\n",
            "üÜî State ID: campeche_demo_002\n"
          ]
        }
      ],
      "source": [
        "# Execute the Campeche example\n",
        "thread_config = execute_campeche_example(\"Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo dobro da temperatura e me retorne o final.\", \"campeche_demo_002\")\n",
        "\n",
        "# Inspect the current state\n",
        "inspect_state(thread_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_state = graph.get_state(thread_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo dobro da temperatura e me retorne o final.', additional_kwargs={}, response_metadata={}, id='a65f4c28-8f32-4b96-ba0e-6007f12aa48f'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ex9IaEu6H7mfXNOR1APUps7V', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 342, 'total_tokens': 354, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrAKrRHC4RHpJpdJiPGXw5PgTYs', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='main_agent', id='run--165f35e5-310e-4b9c-9013-0f8529980766-0', tool_calls=[{'name': 'transfer_to_bob', 'args': {}, 'id': 'call_ex9IaEu6H7mfXNOR1APUps7V', 'type': 'tool_call'}], usage_metadata={'input_tokens': 342, 'output_tokens': 12, 'total_tokens': 354, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Successfully transferred to Bob', name='transfer_to_bob', id='df7f0a14-dbd6-4ced-90fa-74166f9f50db', tool_call_id='call_ex9IaEu6H7mfXNOR1APUps7V'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sr95LqTdiUOJYnlbjF0lX08E', 'function': {'arguments': '{\"location\":\"Campeche\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 284, 'total_tokens': 300, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrCbpwADXuUeJxQQVV7D3XVrOQ2', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Bob', id='run--fb74de96-21bb-45af-925c-befe580e27e9-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Campeche'}, 'id': 'call_sr95LqTdiUOJYnlbjF0lX08E', 'type': 'tool_call'}], usage_metadata={'input_tokens': 284, 'output_tokens': 16, 'total_tokens': 300, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='The weather for Campeche is 26 degrees.', name='get_weather', id='4f933b16-d070-4650-a1cd-8717823483cd', tool_call_id='call_sr95LqTdiUOJYnlbjF0lX08E'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bLsuan9S0AmWHLgOJhnuZgls', 'function': {'arguments': '{}', 'name': 'transfer_to_alice'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 320, 'total_tokens': 332, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrE4PrylH4Cd6FBxxaDqWuQ6HBB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Bob', id='run--f7059bee-a32f-400f-b8f6-8962731b0573-0', tool_calls=[{'name': 'transfer_to_alice', 'args': {}, 'id': 'call_bLsuan9S0AmWHLgOJhnuZgls', 'type': 'tool_call'}], usage_metadata={'input_tokens': 320, 'output_tokens': 12, 'total_tokens': 332, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Successfully transferred to Alice', name='transfer_to_alice', id='0c55acbc-1180-4638-8ded-f1d65c92fe00', tool_call_id='call_bLsuan9S0AmWHLgOJhnuZgls'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_c1xF6WBkTeQFcRhECJkY4m81', 'function': {'arguments': '{\"expression\":\"26 * (2 * 26)\"}', 'name': 'calculate_math'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 277, 'total_tokens': 298, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrFsWNens0vbJqcWUDARSgnvbDv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--16a3f4bd-ce4b-47cb-bbd8-2d113ce6cabe-0', tool_calls=[{'name': 'calculate_math', 'args': {'expression': '26 * (2 * 26)'}, 'id': 'call_c1xF6WBkTeQFcRhECJkY4m81', 'type': 'tool_call'}], usage_metadata={'input_tokens': 277, 'output_tokens': 21, 'total_tokens': 298, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content=\"Could not calculate 26 * (2 * 26). Please use format like '2 + 3' or '10 * 5'\", name='calculate_math', id='abc910ed-4edb-43fe-bca8-01f571c77aa5', tool_call_id='call_c1xF6WBkTeQFcRhECJkY4m81'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fR8OhyW1UeWnokFkFaIbFzw2', 'function': {'arguments': '{\"expression\":\"26 * 52\"}', 'name': 'calculate_math'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 337, 'total_tokens': 354, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrGiOGitunFXH1QdqGNDQkGeJZO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--d5ef51ca-d45c-4a63-bdda-f242c2718562-0', tool_calls=[{'name': 'calculate_math', 'args': {'expression': '26 * 52'}, 'id': 'call_fR8OhyW1UeWnokFkFaIbFzw2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 17, 'total_tokens': 354, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='The result of 26 * 52 is 1352.0', name='calculate_math', id='39ada220-359c-4bfc-b70a-052a538e0268', tool_call_id='call_fR8OhyW1UeWnokFkFaIbFzw2'),\n",
              "  AIMessage(content='O resultado da multiplica√ß√£o da temperatura atual em Campeche (26 graus) pelo dobro da temperatura √© 1352.0.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 378, 'total_tokens': 405, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BrSrHyBXS2suoOvd0cdDXNPm8Bccm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='Alice', id='run--10297bba-65ab-4514-a661-d4566eefa2e0-0', usage_metadata={'input_tokens': 378, 'output_tokens': 27, 'total_tokens': 405, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " 'active_agent': 'Alice',\n",
              " 'temperature': '26 degrees',\n",
              " 'location': 'Campeche',\n",
              " 'math_expression': '26 * 52',\n",
              " 'math_result': 1352.0}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_state.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Additional Utilities and Debugging\n",
        "\n",
        "These utility functions help with debugging and state management of the multi-agent system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Utility functions loaded!\n",
            "üîß Use show_system_info() to see available functions\n"
          ]
        }
      ],
      "source": [
        "def reset_system():\n",
        "    \"\"\"Reset the system state and create a new graph instance\"\"\"\n",
        "    global graph\n",
        "    print(\"üîÑ Resetting multi-agent system...\")\n",
        "    graph = create_multi_agent_system_swarm_mode()\n",
        "    print(\"‚úÖ System reset complete!\")\n",
        "    return graph\n",
        "\n",
        "\n",
        "def debug_checkpointer_state(thread_config):\n",
        "    \"\"\"Debug the checkpointer state in detail\"\"\"\n",
        "    \n",
        "    print(\"\\nüîß DETAILED CHECKPOINTER DEBUG\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        state = graph.get_state(thread_config)\n",
        "        \n",
        "        if state:\n",
        "            print(f\"üìä State Config: {state.config}\")\n",
        "            print(f\"üìç Next Steps: {state.next}\")\n",
        "            print(f\"üîÑ Tasks: {getattr(state, 'tasks', 'Not available')}\")\n",
        "            \n",
        "            print(\"\\nüìã All State Values:\")\n",
        "            for key, value in state.values.items():\n",
        "                if key == 'messages':\n",
        "                    print(f\"  üí¨ {key}: {len(value)} total messages\")\n",
        "                    for i, msg in enumerate(value):\n",
        "                        msg_type = type(msg).__name__\n",
        "                        content = str(msg.content)[:50] + \"...\" if len(str(msg.content)) > 50 else str(msg.content)\n",
        "                        print(f\"    [{i}] {msg_type}: {content}\")\n",
        "                else:\n",
        "                    print(f\"  üéØ {key}: {value}\")\n",
        "        \n",
        "        else:\n",
        "            print(\"‚ùå No state found for the given thread configuration\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Debug error: {e}\")\n",
        "\n",
        "\n",
        "def test_individual_tools():\n",
        "    \"\"\"Test each tool individually\"\"\"\n",
        "    \n",
        "    print(\"\\nüß™ INDIVIDUAL TOOL TESTING\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(\"\\n1. Testing get_weather tool:\")\n",
        "    try:\n",
        "        weather_result = get_weather(\"Campeche\", \"test_tool_call_1\")\n",
        "        print(f\"   Result: {weather_result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "    \n",
        "    print(\"\\n2. Testing calculate_math tool:\")\n",
        "    try:\n",
        "        math_result = calculate_math(\"70 * 3\", \"test_tool_call_2\")\n",
        "        print(f\"   Result: {math_result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "    \n",
        "    print(\"\\n3. Testing ask_user tool:\")\n",
        "    try:\n",
        "        print(\"   Note: ask_user tool requires interrupt mechanism, skipping direct test\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "\n",
        "\n",
        "def show_system_info():\n",
        "    \"\"\"Display system information and configuration\"\"\"\n",
        "    \n",
        "    print(\"\\nüìã SYSTEM INFORMATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(f\"ü§ñ Language Model: {model}\")\n",
        "    print(f\"üîß LangGraph API Mode: {os.environ.get('LANGGRAPH_API', 'false')}\")\n",
        "    print(f\"üìÅ LangGraph API Dir: {os.environ.get('LANGGRAPH_API_DIR', 'Not set')}\")\n",
        "    \n",
        "    # Check if graph has checkpointer\n",
        "    if hasattr(graph, 'checkpointer'):\n",
        "        print(f\"üíæ Checkpointer: {type(graph.checkpointer).__name__}\")\n",
        "    else:\n",
        "        print(\"üíæ Checkpointer: Not available\")\n",
        "    \n",
        "    # Show graph structure\n",
        "    if hasattr(graph, 'nodes'):\n",
        "        print(f\"üï∏Ô∏è Graph Nodes: {list(graph.nodes.keys()) if graph.nodes else 'Not available'}\")\n",
        "    \n",
        "    \n",
        "print(\"‚úÖ Utility functions loaded!\")\n",
        "print(\"üîß Use show_system_info() to see available functions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìã SYSTEM INFORMATION\n",
            "==================================================\n",
            "ü§ñ Language Model: client=<openai.resources.chat.completions.completions.Completions object at 0x10f819c70> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f81bb00> root_client=<openai.OpenAI object at 0x10f819970> root_async_client=<openai.AsyncOpenAI object at 0x10f819280> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********')\n",
            "üîß LangGraph API Mode: false\n",
            "üìÅ LangGraph API Dir: Not set\n",
            "üíæ Checkpointer: InMemorySaver\n",
            "üï∏Ô∏è Graph Nodes: ['__start__', 'main_agent', 'Alice', 'Bob', 'cleanup_messages']\n",
            "\n",
            "üß™ INDIVIDUAL TOOL TESTING\n",
            "==================================================\n",
            "\n",
            "1. Testing get_weather tool:\n",
            "üå§Ô∏è Getting weather for Campeche\n",
            "   Result: Command(update={'location': 'Campeche', 'temperature': '20 degrees', 'date': '2025-01-20', 'time': '12:20:00', 'tool_call_id': 'test_tool_call_1', 'messages': [ToolMessage(content='The weather for Campeche is 20 degrees.', tool_call_id='test_tool_call_1')]})\n",
            "\n",
            "2. Testing calculate_math tool:\n",
            "üî¢ Calculating math for 70 * 3\n",
            "   Result: Command(update={'math_expression': '70 * 3', 'math_result': 210.0, 'messages': [ToolMessage(content='The result of 70 * 3 is 210.0', tool_call_id='test_tool_call_2')]})\n",
            "\n",
            "3. Testing ask_user tool:\n",
            "   Note: ask_user tool requires interrupt mechanism, skipping direct test\n"
          ]
        }
      ],
      "source": [
        "# Show system information and available functions\n",
        "show_system_info()\n",
        "\n",
        "# Test individual tools\n",
        "test_individual_tools()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. Summary and Conclusion\n",
        "\n",
        "This notebook demonstrates a sophisticated multi-agent system using LangGraph that successfully handles complex, multi-step tasks requiring coordination between specialized agents.\n",
        "\n",
        "### Key Features Demonstrated:\n",
        "\n",
        "1. **ü§ñ Multi-Agent Coordination**: Main agent orchestrates task distribution\n",
        "2. **üîß Specialized Agents**: \n",
        "   - Alice (mathematics)\n",
        "   - Bob (weather with personality)\n",
        "3. **üíæ Memory Checkpointer**: Complete state tracking and inspection\n",
        "4. **üîÑ Agent Handoffs**: Seamless task delegation\n",
        "5. **üë§ Human-in-the-Loop**: Interactive user input with interrupts\n",
        "6. **üìä State Management**: Real-time monitoring and debugging\n",
        "\n",
        "### Expected Workflow:\n",
        "1. User asks for Campeche temperature and multiplication\n",
        "2. Main Agent analyzes and plans execution\n",
        "3. Bob retrieves weather information (70¬∞)\n",
        "4. Main Agent requests the mystery number from user\n",
        "5. Alice calculates the final result (70 √ó user_number)\n",
        "6. System provides complete calculation result\n",
        "\n",
        "### Memory Checkpointer Benefits:\n",
        "- **State Recovery**: Resume execution after interrupts\n",
        "- **Debugging**: Inspect state at any point\n",
        "- **Audit Trail**: Complete message and state history\n",
        "- **Error Recovery**: Rollback and retry capabilities\n",
        "\n",
        "### Next Steps:\n",
        "- Experiment with different queries\n",
        "- Add more specialized agents\n",
        "- Implement more complex calculations\n",
        "- Enhance error handling and validation\n",
        "\n",
        "The system successfully demonstrates enterprise-grade multi-agent coordination with comprehensive state management and debugging capabilities.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
