# üìã **Plano de Implementa√ß√£o - PoC RAG Agentico TCE-PA**

## üéØ **Vis√£o Geral da Estrat√©gia**

### **Objetivo da PoC**
Validar o fluxo completo do pipeline RAG agentico com **comportamento real√≠stico** usando LLM structured output para simular funcionalidades complexas, mantendo a arquitetura modular para facilitar a migra√ß√£o posterior para implementa√ß√µes reais.

### **Filosofia de Implementa√ß√£o**
- **Flow Real**: Pipeline completo funcional com LangGraph
- **Respostas Real√≠sticas**: Mocks gerados por LLM bem instru√≠das
- **Modularidade**: Substitui√ß√£o simples de mocks por implementa√ß√µes reais
- **Valida√ß√£o Completa**: Comportamento id√™ntico ao sistema final

---

## üèóÔ∏è **Estrutura de Diret√≥rios**

```
sample_agent/agents/tce_swarm/
‚îú‚îÄ‚îÄ README.md                    # ‚úÖ Documenta√ß√£o completa
‚îú‚îÄ‚îÄ PLANO_DE_IMPLEMENTACAO.md    # üìã Este documento
‚îú‚îÄ‚îÄ rag/                         # üÜï M√≥dulo RAG espec√≠fico
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                 # ü§ñ LLM helper function
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                   # üîÑ N√≥s do pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_db_setup.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query_analysis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunk_strategy.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_ingestion.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_retrieval.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ relevance_grading.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ context_enrichment.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reranking.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ response_generation.py
‚îÇ   ‚îú‚îÄ‚îÄ processors/              # üìñ Processadores especializados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docling_processor.py # (Mock via LLM)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chonkie_processor.py # (Mock via LLM)
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # üìä Modelos Pydantic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunks.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ responses.py
‚îÇ   ‚îî‚îÄ‚îÄ graph.py                 # üï∏Ô∏è Subgrafo RAG
‚îú‚îÄ‚îÄ main_agent.py                # ü§ñ Agente principal
‚îú‚îÄ‚îÄ rag_agent.py                 # üìö Agente RAG
‚îú‚îÄ‚îÄ search_agent.py              # üîç Agente de busca
‚îú‚îÄ‚îÄ tools.py                     # üõ†Ô∏è Ferramentas mockadas
‚îú‚îÄ‚îÄ states.py                    # üìä Estados consolidados
‚îú‚îÄ‚îÄ graph.py                     # üï∏Ô∏è Grafo principal
‚îî‚îÄ‚îÄ demo.py                      # üéÆ Demonstra√ß√£o
```

---

## ü§ñ **LLM Helper - Core da Estrat√©gia**

### **Fun√ß√£o Utilit√°ria Central**

```python
# sample_agent/agents/tce_swarm/rag/utils.py

from typing import Optional, Any, Dict, List, Union
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel
import json
import logging

logger = logging.getLogger(__name__)

def llm(instruction: str, output_model: Optional[BaseModel] = None, **kwargs) -> Any:
    """
    Fun√ß√£o auxiliar para simular funcionalidades complexas via LLM structured output.
    
    Args:
        instruction: Instru√ß√£o detalhada para a LLM
        output_model: Modelo Pydantic para structured output (opcional)
        **kwargs: Par√¢metros adicionais para contexto
    
    Returns:
        Resposta estruturada conforme output_model ou texto simples
    """
    
    # Configura√ß√£o da LLM
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=2000
    )
    
    # Contexto adicional
    context_str = ""
    if kwargs:
        context_str = f"\n\nContexto Adicional:\n{json.dumps(kwargs, indent=2, ensure_ascii=False)}"
    
    # Prompt base
    base_prompt = f"""
Sintetize dados estruturados conforme especificado.

INSTRU√á√ÉO ESPEC√çFICA:
{instruction}

DIRETRIZES:
- Gere dados real√≠sticos e consistentes
- Mantenha estrutura conforme solicitado
- Use terminologia t√©cnica apropriada
- Considere cen√°rios variados
- Foque na qualidade da s√≠ntese

{context_str}
"""
    
    try:
        if output_model:
            # Structured output com Pydantic
            parser = PydanticOutputParser(pydantic_object=output_model)
            prompt = PromptTemplate(
                template=base_prompt + "\n\nFORMATO DE SA√çDA:\n{format_instructions}",
                input_variables=[],
                partial_variables={"format_instructions": parser.get_format_instructions()}
            )
            
            chain = prompt | model | parser
            response = chain.invoke({})
            
            logger.info(f"LLM Mock Response: {type(response).__name__}")
            return response
        else:
            # Resposta em texto simples
            response = model.invoke(base_prompt)
            logger.info(f"LLM Mock Response: {len(response.content)} chars")
            return response.content
            
    except Exception as e:
        logger.error(f"LLM Mock Error: {str(e)}")
        # Fallback para dados default
        if output_model:
            return output_model()
        else:
            return f"Mock response for: {instruction[:50]}..."

# Fun√ß√£o espec√≠fica para simular processamento de documentos
def mock_document_processing(file_path: str, doc_type: str) -> Dict[str, Any]:
    """Simula processamento Docling via LLM"""
    
    instruction = f"""
    Simule o processamento de um documento oficial usando parser estruturado.
    
    Documento: {file_path}
    Tipo: {doc_type}
    
    Retorne dados real√≠sticos incluindo:
    - Conte√∫do markdown extra√≠do
    - Estrutura hier√°rquica detectada
    - Metadados do documento
    - Score de qualidade
    """
    
    from .models.documents import DoclingProcessingResult
    
    return llm(instruction, DoclingProcessingResult, 
               file_path=file_path, doc_type=doc_type)

# Fun√ß√£o para simular chunking
def mock_chunking(content: str, strategy: str, config: Dict[str, Any]) -> List[str]:
    """Simula chunking Chonkie via LLM"""
    
    instruction = f"""
    Simule o chunking de conte√∫do estruturado usando estrat√©gia {strategy}.
    
    Conte√∫do: {content[:200]}...
    Estrat√©gia: {strategy}
    Configura√ß√£o: {config}
    
    Retorne lista de chunks real√≠sticos mantendo estrutura hier√°rquica.
    """
    
    from .models.chunks import ChunkingResult
    
    return llm(instruction, ChunkingResult, 
               content=content, strategy=strategy, config=config)

# Fun√ß√£o para simular vector database
def mock_vector_search(query: str, collection: str, filters: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Simula busca no vector database via LLM"""
    
    instruction = f"""
    Simule busca sem√¢ntica em vector database especializado em documentos oficiais.
    
    Query: {query}
    Collection: {collection}
    Filtros: {filters}
    
    Retorne chunks relevantes com scores real√≠sticos.
    """
    
    from .models.chunks import VectorSearchResult
    
    return llm(instruction, VectorSearchResult, 
               query=query, collection=collection, filters=filters)
```

---

## üìä **Modelos Pydantic - Structured Output**

### **Modelos para Documentos**

```python
# sample_agent/agents/tce_swarm/rag/models/documents.py

from pydantic import BaseModel, Field
from typing import Dict, List, Any, Optional
from datetime import datetime

class DocumentStructure(BaseModel):
    """Estrutura hier√°rquica detectada no documento"""
    header: str = Field(description="Cabe√ßalho principal")
    sections: List[Dict[str, Any]] = Field(description="Se√ß√µes hier√°rquicas")
    articles: List[Dict[str, Any]] = Field(description="Artigos numerados")
    annexes: List[str] = Field(description="Anexos identificados")
    signatures: List[str] = Field(description="Assinaturas finais")

class DoclingProcessingResult(BaseModel):
    """Resultado do processamento Docling"""
    success: bool = Field(description="Status do processamento")
    method: str = Field(description="M√©todo utilizado")
    raw_markdown: str = Field(description="Conte√∫do markdown extra√≠do")
    structured_content: DocumentStructure = Field(description="Estrutura hier√°rquica detectada")
    metadata: Dict[str, Any] = Field(description="Metadados enriquecidos")
    confidence: float = Field(description="Score de confian√ßa", ge=0.0, le=1.0)
    processing_time: float = Field(description="Tempo de processamento")
    tables: List[Dict[str, Any]] = Field(description="Tabelas extra√≠das")
```

### **Modelos para Chunks**

```python
# sample_agent/agents/tce_swarm/rag/models/chunks.py

from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional

class ChunkResult(BaseModel):
    """Resultado de um chunk individual"""
    content: str = Field(description="Conte√∫do do chunk")
    metadata: Dict[str, Any] = Field(description="Metadados associados")
    chunk_id: str = Field(description="ID √∫nico")
    
class ChunkingResult(BaseModel):
    """Resultado do processo de chunking"""
    chunks: List[ChunkResult] = Field(description="Lista de chunks gerados")
    strategy_used: str = Field(description="Estrat√©gia utilizada")
    total_chunks: int = Field(description="N√∫mero total de chunks")
    processing_time: float = Field(description="Tempo de processamento")

class VectorSearchResult(BaseModel):
    """Resultado da busca no vector database"""
    chunks: List[ChunkResult] = Field(description="Chunks encontrados")
    query: str = Field(description="Query utilizada")
    total_results: int = Field(description="Total de resultados")
    search_time: float = Field(description="Tempo de busca")

class GradedChunk(BaseModel):
    """Chunk com avalia√ß√£o de relev√¢ncia"""
    chunk: ChunkResult = Field(description="Chunk original")
    relevance_score: float = Field(description="Score de relev√¢ncia", ge=0.0, le=1.0)
    confidence: float = Field(description="Confian√ßa na avalia√ß√£o", ge=0.0, le=1.0)
```

---

## üîÑ **Implementa√ß√£o dos N√≥s do Pipeline**

### **1. Query Analysis Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/query_analysis.py

from ..utils import llm
from ..models.state import TCE_RAG_State
from ..models.responses import QueryAnalysisResult

def query_analysis_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Analisa query usando LLM structured output para classifica√ß√£o inteligente
    """
    
    instruction = f"""
    Analise a consulta e classifique conforme padr√µes de documentos oficiais do tribunal de contas:
    
    Query: "{state.original_query}"
    
    Determine:
    1. Tipo de consulta (legislation, acordao, resolucao, jurisprudencia)
    2. Complexidade (simple, medium, complex)
    3. Contexto temporal necess√°rio
    4. Bases de dados relevantes
    5. Se necessita ingest√£o de novos documentos
    
    Considere padr√µes t√≠picos de consultas em documentos oficiais.
    """
    
    analysis = llm(instruction, QueryAnalysisResult, 
                   query=state.original_query, 
                   user_context=state.user_id)
    
    return state.copy(
        processed_query=analysis.processed_query,
        query_type=analysis.query_type,
        query_complexity=analysis.query_complexity,
        target_databases=analysis.target_databases,
        temporal_context=analysis.temporal_context,
        needs_ingestion=analysis.needs_ingestion
    )
```

### **2. Chunk Strategy Selection Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/chunk_strategy.py

from ..utils import llm
from ..models.state import TCE_RAG_State
from ..models.responses import ChunkStrategyResult

def chunk_strategy_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Seleciona estrat√©gia de chunking via LLM baseada no contexto
    """
    
    instruction = f"""
    Selecione a estrat√©gia de chunking mais adequada para:
    
    Tipo de Consulta: {state.query_type}
    Complexidade: {state.query_complexity}
    Bases de Dados: {state.target_databases}
    
    Estrat√©gias dispon√≠veis:
    - recursive: Estrutura hier√°rquica preservada
    - semantic: Agrupamento sem√¢ntico
    - sdpm: Precis√£o sem√¢ntica m√°xima
    - late: Contexto global preservado
    
    Considere caracter√≠sticas espec√≠ficas de documentos estruturados.
    """
    
    strategy = llm(instruction, ChunkStrategyResult,
                   query_type=state.query_type,
                   complexity=state.query_complexity,
                   databases=state.target_databases)
    
    return state.copy(
        selected_chunker=strategy.selected_strategy,
        chunk_size=strategy.chunk_size,
        chunk_overlap=strategy.chunk_overlap,
        chunking_metadata=strategy.configuration
    )
```

### **3. Document Ingestion Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/document_ingestion.py

from ..utils import llm, mock_document_processing, mock_chunking
from ..models.state import TCE_RAG_State
from ..models.responses import IngestionResult

def document_ingestion_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Processa ingest√£o completa: Docling ‚Üí Chunking ‚Üí Vector DB
    """
    
    if not state.needs_ingestion or not state.documents_to_ingest:
        return state
    
    ingestion_results = {}
    
    for doc_info in state.documents_to_ingest:
        # 1. Processamento Docling (Mock)
        parsing_result = mock_document_processing(
            doc_info["file_path"], 
            doc_info.get("type", "expediente")
        )
        
        # 2. Chunking com estrat√©gia selecionada (Mock)
        chunks = mock_chunking(
            parsing_result.raw_markdown,
            state.selected_chunker,
            state.chunking_metadata
        )
        
        # 3. Simula√ß√£o de storage no vector database
        instruction = f"""
        Simule o armazenamento de chunks no vector database:
        
        Chunks: {len(chunks.chunks)} chunks gerados
        Collection: {state.collection_names}
        User ID: {state.user_id}
        Document Scope: {state.document_scope}
        
        Retorne status de ingestion real√≠stico.
        """
        
        storage_result = llm(instruction, IngestionResult,
                           chunks=chunks.chunks,
                           collection=state.collection_names,
                           user_id=state.user_id)
        
        ingestion_results[doc_info["id"]] = storage_result
    
    return state.copy(
        ingestion_status=ingestion_results,
        needs_ingestion=False,
        user_documents=[doc["id"] for doc in state.documents_to_ingest]
    )
```

### **4. Document Retrieval Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/document_retrieval.py

from ..utils import llm, mock_vector_search
from ..models.state import TCE_RAG_State
from ..models.responses import RetrievalResult

def document_retrieval_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Executa retrieval h√≠brido nos chunks j√° armazenados
    """
    
    # Configurar filtros baseados no escopo
    filters = {
        "document_scope": state.document_scope
    }
    
    if state.document_scope == "user_specific":
        filters["user_id"] = state.user_id
    elif state.document_scope == "session_specific":
        filters["session_id"] = state.session_id
    
    # Busca em m√∫ltiplas collections
    all_chunks = []
    
    for collection in state.collection_names:
        # Mock da busca sem√¢ntica
        semantic_results = mock_vector_search(
            state.processed_query,
            collection,
            {**filters, "search_type": "semantic"}
        )
        
        # Mock da busca por keywords
        keyword_results = mock_vector_search(
            state.processed_query,
            collection,
            {**filters, "search_type": "keyword"}
        )
        
        # Combinar resultados
        instruction = f"""
        Combine resultados de busca sem√¢ntica e keyword:
        
        Semantic Results: {len(semantic_results.chunks)} chunks
        Keyword Results: {len(keyword_results.chunks)} chunks
        
        Pesos: Semantic 0.7, Keyword 0.3
        
        Retorne top 20 chunks combinados sem duplicatas.
        """
        
        combined = llm(instruction, RetrievalResult,
                      semantic_results=semantic_results.chunks,
                      keyword_results=keyword_results.chunks,
                      query=state.processed_query)
        
        all_chunks.extend(combined.chunks)
    
    # Deduplica√ß√£o e ranking final
    instruction = f"""
    Deduplique e rankeie {len(all_chunks)} chunks por relev√¢ncia:
    
    Query: {state.processed_query}
    
    Retorne top 10 chunks √∫nicos ordenados por relev√¢ncia.
    """
    
    final_result = llm(instruction, RetrievalResult,
                      all_chunks=all_chunks,
                      query=state.processed_query)
    
    return state.copy(
        retrieved_chunks=final_result.chunks,
        retrieval_time=final_result.processing_time,
        vector_db_queries=len(state.collection_names) * 2
    )
```

---

## üéØ **Estrat√©gia de Migra√ß√£o Mock ‚Üí Real**

### **1. Substitui√ß√£o Modular**

```python
# Estrutura atual (PoC)
from .utils import llm, mock_document_processing

def document_ingestion_node(state):
    parsing_result = mock_document_processing(file_path, doc_type)
    # ... resto do c√≥digo

# Estrutura futura (Produ√ß√£o)
from .processors.docling_processor import DoclingProcessor

def document_ingestion_node(state):
    processor = DoclingProcessor()
    parsing_result = processor.process_document(file_path, doc_type)
    # ... resto do c√≥digo ID√äNTICO
```

### **2. Interface Consistente**

Todos os mocks retornam **exatamente a mesma estrutura** que as implementa√ß√µes reais:

```python
# Mock e Real retornam DoclingProcessingResult
class DoclingProcessingResult(BaseModel):
    success: bool
    raw_markdown: str
    structured_content: TCEStructure
    metadata: Dict[str, Any]
    confidence: float
```

---

## üß™ **Valida√ß√£o e Testes**

### **1. Testes de Integra√ß√£o**

```python
# test_rag_pipeline.py

def test_full_pipeline():
    """Testa pipeline completo com mocks"""
    
    state = TCE_RAG_State(
        original_query="Qual √© o prazo para recurso em processos TCE-PA?",
        user_id="test_user",
        session_id="test_session"
    )
    
    # Executa pipeline completo
    result = tce_rag_subgraph.invoke(state)
    
    # Valida√ß√µes
    assert result.generated_response
    assert result.quality_score > 0.7
    assert len(result.citations) > 0
    assert result.processing_time < 10.0
```

### **2. Testes de Comportamento**

```python
def test_realistic_behavior():
    """Verifica se mocks geram comportamento real√≠stico"""
    
    # Teste com diferentes tipos de documento
    for doc_type in ["legislation", "acordao", "resolucao"]:
        result = mock_document_processing(f"test_{doc_type}.pdf", doc_type)
        
        # Comportamento esperado por tipo
        if doc_type == "legislation":
            assert len(result.structured_content.articles) > 0
        elif doc_type == "acordao":
            assert "AC√ìRD√ÉO" in result.structured_content.header
```

## üéØ **Vantagens da Abordagem**

### **‚úÖ Benef√≠cios Imediatos**
- **Valida√ß√£o R√°pida**: Pipeline completo em dias, n√£o semanas
- **Comportamento Real√≠stico**: LLM gera respostas contextualmente apropriadas
- **Modularidade**: Migra√ß√£o sem refatora√ß√£o de arquitetura
- **Teste Completo**: Fluxo end-to-end funcionando

### **‚úÖ Benef√≠cios Futuros**
- **Migra√ß√£o Suave**: Substitui√ß√£o gradual componente por componente
- **Risco Reduzido**: Arquitetura validada antes da implementa√ß√£o real
- **Feedback Antecipado**: Usu√°rios podem avaliar comportamento
- **Documenta√ß√£o Viva**: Especifica√ß√µes testadas e funcionais

---

## üîß **Comandos de Execu√ß√£o**

### **Setup da PoC**
```bash
# Instalar depend√™ncias
uv sync

# Configurar ambiente
export USE_MOCKS=true
export OPENAI_API_KEY=your_key

# Executar testes
python -m pytest sample_agent/agents/tce_swarm/rag/tests/

# Demo completa
python sample_agent/agents/tce_swarm/demo.py --rag-poc
```

### **Migra√ß√£o para Produ√ß√£o**
```bash
# Desabilitar mocks
export USE_MOCKS=false

# Instalar depend√™ncias reais
uv add docling chonkie-ai chromadb

# Executar com implementa√ß√µes reais
python sample_agent/agents/tce_swarm/demo.py --production
```

---

## üìã **Resumo Executivo**

### **Estrat√©gia**
**PoC Inteligente** usando LLM structured output para simular comportamento real√≠stico do pipeline RAG agentico, mantendo arquitetura modular para migra√ß√£o suave.

### **Entreg√°veis**
1. **Pipeline RAG Completo** com 8 n√≥s funcionais
2. **Respostas Real√≠sticas** via LLM bem instru√≠das
3. **Arquitetura Modular** para migra√ß√£o gradual
4. **Valida√ß√£o End-to-End** com m√©tricas e observabilidade

### **Timeline**
**11 dias** para PoC completa funcional, pronta para avalia√ß√£o e feedback.

### **Pr√≥ximos Passos**
1. **Aprova√ß√£o** do plano de implementa√ß√£o
2. **In√≠cio da Fase 1** - Setup da estrutura base
3. **Implementa√ß√£o iterativa** com valida√ß√£o cont√≠nua
4. **Demo e avalia√ß√£o** com stakeholders

**Status**: üìã **Plano aprovado - Pronto para implementa√ß√£o** 