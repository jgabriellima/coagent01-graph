# ğŸ“‹ **Plano de ImplementaÃ§Ã£o - PoC RAG Agentico TCE-PA**

## ğŸ¯ **VisÃ£o Geral da EstratÃ©gia**

### **Objetivo da PoC**
Validar o fluxo completo do pipeline RAG agentico com **comportamento realÃ­stico** usando LLM structured output para simular funcionalidades complexas, mantendo a arquitetura modular para facilitar a migraÃ§Ã£o posterior para implementaÃ§Ãµes reais.

### **Filosofia de ImplementaÃ§Ã£o**
- **Flow Real**: Pipeline completo funcional com LangGraph
- **Respostas RealÃ­sticas**: Mocks gerados por LLM bem instruÃ­das
- **Modularidade**: SubstituiÃ§Ã£o simples de mocks por implementaÃ§Ãµes reais
- **ValidaÃ§Ã£o Completa**: Comportamento idÃªntico ao sistema final

---

## ğŸ—ï¸ **Estrutura de DiretÃ³rios**

```
sample_agent/agents/tce_swarm/
â”œâ”€â”€ README.md                    # âœ… DocumentaÃ§Ã£o completa
â”œâ”€â”€ PLANO_DE_IMPLEMENTACAO.md    # ğŸ“‹ Este documento
â”œâ”€â”€ rag/                         # ğŸ†• MÃ³dulo RAG especÃ­fico
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                 # ğŸ¤– LLM helper function
â”‚   â”œâ”€â”€ nodes/                   # ğŸ”„ NÃ³s do pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_db_setup.py
â”‚   â”‚   â”œâ”€â”€ query_analysis.py
â”‚   â”‚   â”œâ”€â”€ chunk_strategy.py
â”‚   â”‚   â”œâ”€â”€ document_ingestion.py
â”‚   â”‚   â”œâ”€â”€ document_retrieval.py
â”‚   â”‚   â”œâ”€â”€ relevance_grading.py
â”‚   â”‚   â”œâ”€â”€ context_enrichment.py
â”‚   â”‚   â”œâ”€â”€ reranking.py
â”‚   â”‚   â””â”€â”€ response_generation.py
â”‚   â”œâ”€â”€ processors/              # ğŸ“– Processadores especializados
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docling_processor.py # (Mock via LLM)
â”‚   â”‚   â””â”€â”€ chonkie_processor.py # (Mock via LLM)
â”‚   â”œâ”€â”€ models/                  # ğŸ“Š Modelos Pydantic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py
â”‚   â”‚   â”œâ”€â”€ chunks.py
â”‚   â”‚   â”œâ”€â”€ documents.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â””â”€â”€ graph.py                 # ğŸ•¸ï¸ Subgrafo RAG
â”œâ”€â”€ main_agent.py                # ğŸ¤– Agente principal
â”œâ”€â”€ rag_agent.py                 # ğŸ“š Agente RAG
â”œâ”€â”€ search_agent.py              # ğŸ” Agente de busca
â”œâ”€â”€ tools.py                     # ğŸ› ï¸ Ferramentas mockadas
â”œâ”€â”€ states.py                    # ğŸ“Š Estados consolidados
â”œâ”€â”€ graph.py                     # ğŸ•¸ï¸ Grafo principal
â””â”€â”€ demo.py                      # ğŸ® DemonstraÃ§Ã£o
```

---

## ğŸ¤– **LLM Helper - Core da EstratÃ©gia**

### **FunÃ§Ã£o UtilitÃ¡ria Central**

```python
# sample_agent/agents/tce_swarm/rag/utils.py

from typing import Optional, Any, Dict, List, Union
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel
import json
import logging

logger = logging.getLogger(__name__)

def llm(instruction: str, output_model: Optional[BaseModel] = None, **kwargs) -> Any:
    """
    FunÃ§Ã£o auxiliar para simular funcionalidades complexas via LLM structured output.
    
    Args:
        instruction: InstruÃ§Ã£o detalhada para a LLM
        output_model: Modelo Pydantic para structured output (opcional)
        **kwargs: ParÃ¢metros adicionais para contexto
    
    Returns:
        Resposta estruturada conforme output_model ou texto simples
    """
    
    # ConfiguraÃ§Ã£o da LLM
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        max_tokens=2000
    )
    
    # Contexto adicional
    context_str = ""
    if kwargs:
        context_str = f"\n\nContexto Adicional:\n{json.dumps(kwargs, indent=2, ensure_ascii=False)}"
    
    # Prompt base
    base_prompt = f"""
Sintetize dados estruturados conforme especificado.

INSTRUÃ‡ÃƒO ESPECÃFICA:
{instruction}

DIRETRIZES:
- Gere dados realÃ­sticos e consistentes
- Mantenha estrutura conforme solicitado
- Use terminologia tÃ©cnica apropriada
- Considere cenÃ¡rios variados
- Foque na qualidade da sÃ­ntese

{context_str}
"""
    
    try:
        if output_model:
            # Structured output com Pydantic
            parser = PydanticOutputParser(pydantic_object=output_model)
            prompt = PromptTemplate(
                template=base_prompt + "\n\nFORMATO DE SAÃDA:\n{format_instructions}",
                input_variables=[],
                partial_variables={"format_instructions": parser.get_format_instructions()}
            )
            
            chain = prompt | model | parser
            response = chain.invoke({})
            
            logger.info(f"LLM Mock Response: {type(response).__name__}")
            return response
        else:
            # Resposta em texto simples
            response = model.invoke(base_prompt)
            logger.info(f"LLM Mock Response: {len(response.content)} chars")
            return response.content
            
    except Exception as e:
        logger.error(f"LLM Mock Error: {str(e)}")
        # Fallback para dados default
        if output_model:
            return output_model()
        else:
            return f"Mock response for: {instruction[:50]}..."

# FunÃ§Ã£o especÃ­fica para simular processamento de documentos
def mock_document_processing(file_path: str, doc_type: str) -> Dict[str, Any]:
    """Simula processamento Docling via LLM"""
    
    instruction = f"""
    Simule o processamento de um documento oficial usando parser estruturado.
    
    Documento: {file_path}
    Tipo: {doc_type}
    
    Retorne dados realÃ­sticos incluindo:
    - ConteÃºdo markdown extraÃ­do
    - Estrutura hierÃ¡rquica detectada
    - Metadados do documento
    - Score de qualidade
    """
    
    from .models.documents import DoclingProcessingResult
    
    return llm(instruction, DoclingProcessingResult, 
               file_path=file_path, doc_type=doc_type)

# FunÃ§Ã£o para simular chunking
def mock_chunking(content: str, strategy: str, config: Dict[str, Any]) -> List[str]:
    """Simula chunking Chonkie via LLM"""
    
    instruction = f"""
    Simule o chunking de conteÃºdo estruturado usando estratÃ©gia {strategy}.
    
    ConteÃºdo: {content[:200]}...
    EstratÃ©gia: {strategy}
    ConfiguraÃ§Ã£o: {config}
    
    Retorne lista de chunks realÃ­sticos mantendo estrutura hierÃ¡rquica.
    """
    
    from .models.chunks import ChunkingResult
    
    return llm(instruction, ChunkingResult, 
               content=content, strategy=strategy, config=config)

# FunÃ§Ã£o para simular vector database
def mock_vector_search(query: str, collection: str, filters: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Simula busca no vector database via LLM"""
    
    instruction = f"""
    Simule busca semÃ¢ntica em vector database especializado em documentos oficiais.
    
    Query: {query}
    Collection: {collection}
    Filtros: {filters}
    
    Retorne chunks relevantes com scores realÃ­sticos.
    """
    
    from .models.chunks import VectorSearchResult
    
    return llm(instruction, VectorSearchResult, 
               query=query, collection=collection, filters=filters)
```

---

## ğŸ“Š **Modelos Pydantic - Structured Output**

### **Modelos para Documentos**

```python
# sample_agent/agents/tce_swarm/rag/models/documents.py

from pydantic import BaseModel, Field
from typing import Dict, List, Any, Optional
from datetime import datetime

class DocumentStructure(BaseModel):
    """Estrutura hierÃ¡rquica detectada no documento"""
    header: str = Field(description="CabeÃ§alho principal")
    sections: List[Dict[str, Any]] = Field(description="SeÃ§Ãµes hierÃ¡rquicas")
    articles: List[Dict[str, Any]] = Field(description="Artigos numerados")
    annexes: List[str] = Field(description="Anexos identificados")
    signatures: List[str] = Field(description="Assinaturas finais")

class DoclingProcessingResult(BaseModel):
    """Resultado do processamento Docling"""
    success: bool = Field(description="Status do processamento")
    method: str = Field(description="MÃ©todo utilizado")
    raw_markdown: str = Field(description="ConteÃºdo markdown extraÃ­do")
    structured_content: DocumentStructure = Field(description="Estrutura hierÃ¡rquica detectada")
    metadata: Dict[str, Any] = Field(description="Metadados enriquecidos")
    confidence: float = Field(description="Score de confianÃ§a", ge=0.0, le=1.0)
    processing_time: float = Field(description="Tempo de processamento")
    tables: List[Dict[str, Any]] = Field(description="Tabelas extraÃ­das")
```

### **Modelos para Chunks**

```python
# sample_agent/agents/tce_swarm/rag/models/chunks.py

from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional

class ChunkResult(BaseModel):
    """Resultado de um chunk individual"""
    content: str = Field(description="ConteÃºdo do chunk")
    metadata: Dict[str, Any] = Field(description="Metadados associados")
    chunk_id: str = Field(description="ID Ãºnico")
    
class ChunkingResult(BaseModel):
    """Resultado do processo de chunking"""
    chunks: List[ChunkResult] = Field(description="Lista de chunks gerados")
    strategy_used: str = Field(description="EstratÃ©gia utilizada")
    total_chunks: int = Field(description="NÃºmero total de chunks")
    processing_time: float = Field(description="Tempo de processamento")

class VectorSearchResult(BaseModel):
    """Resultado da busca no vector database"""
    chunks: List[ChunkResult] = Field(description="Chunks encontrados")
    query: str = Field(description="Query utilizada")
    total_results: int = Field(description="Total de resultados")
    search_time: float = Field(description="Tempo de busca")

class GradedChunk(BaseModel):
    """Chunk com avaliaÃ§Ã£o de relevÃ¢ncia"""
    chunk: ChunkResult = Field(description="Chunk original")
    relevance_score: float = Field(description="Score de relevÃ¢ncia", ge=0.0, le=1.0)
    confidence: float = Field(description="ConfianÃ§a na avaliaÃ§Ã£o", ge=0.0, le=1.0)
```

---

## ğŸ”„ **ImplementaÃ§Ã£o dos NÃ³s do Pipeline**

### **1. Query Analysis Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/query_analysis.py

from ..utils import llm
from ..models.state import TCE_RAG_State
from ..models.responses import QueryAnalysisResult

def query_analysis_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Analisa query usando LLM structured output para classificaÃ§Ã£o inteligente
    """
    
    instruction = f"""
    Analise a consulta e classifique conforme padrÃµes de documentos oficiais do tribunal de contas:
    
    Query: "{state.original_query}"
    
    Determine:
    1. Tipo de consulta (legislation, acordao, resolucao, jurisprudencia)
    2. Complexidade (simple, medium, complex)
    3. Contexto temporal necessÃ¡rio
    4. Bases de dados relevantes
    5. Se necessita ingestÃ£o de novos documentos
    
    Considere padrÃµes tÃ­picos de consultas em documentos oficiais.
    """
    
    analysis = llm(instruction, QueryAnalysisResult, 
                   query=state.original_query, 
                   user_context=state.user_id)
    
    return state.copy(
        processed_query=analysis.processed_query,
        query_type=analysis.query_type,
        query_complexity=analysis.query_complexity,
        target_databases=analysis.target_databases,
        temporal_context=analysis.temporal_context,
        needs_ingestion=analysis.needs_ingestion
    )
```

### **2. Chunk Strategy Selection Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/chunk_strategy.py

from ..utils import llm
from ..models.state import TCE_RAG_State
from ..models.responses import ChunkStrategyResult

def chunk_strategy_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Seleciona estratÃ©gia de chunking via LLM baseada no contexto
    """
    
    instruction = f"""
    Selecione a estratÃ©gia de chunking mais adequada para:
    
    Tipo de Consulta: {state.query_type}
    Complexidade: {state.query_complexity}
    Bases de Dados: {state.target_databases}
    
    EstratÃ©gias disponÃ­veis:
    - recursive: Estrutura hierÃ¡rquica preservada
    - semantic: Agrupamento semÃ¢ntico
    - sdpm: PrecisÃ£o semÃ¢ntica mÃ¡xima
    - late: Contexto global preservado
    
    Considere caracterÃ­sticas especÃ­ficas de documentos estruturados.
    """
    
    strategy = llm(instruction, ChunkStrategyResult,
                   query_type=state.query_type,
                   complexity=state.query_complexity,
                   databases=state.target_databases)
    
    return state.copy(
        selected_chunker=strategy.selected_strategy,
        chunk_size=strategy.chunk_size,
        chunk_overlap=strategy.chunk_overlap,
        chunking_metadata=strategy.configuration
    )
```

### **3. Document Ingestion Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/document_ingestion.py

from ..utils import llm, mock_document_processing, mock_chunking
from ..models.state import TCE_RAG_State
from ..models.responses import IngestionResult

def document_ingestion_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Processa ingestÃ£o completa: Docling â†’ Chunking â†’ Vector DB
    """
    
    if not state.needs_ingestion or not state.documents_to_ingest:
        return state
    
    ingestion_results = {}
    
    for doc_info in state.documents_to_ingest:
        # 1. Processamento Docling (Mock)
        parsing_result = mock_document_processing(
            doc_info["file_path"], 
            doc_info.get("type", "expediente")
        )
        
        # 2. Chunking com estratÃ©gia selecionada (Mock)
        chunks = mock_chunking(
            parsing_result.raw_markdown,
            state.selected_chunker,
            state.chunking_metadata
        )
        
        # 3. SimulaÃ§Ã£o de storage no vector database
        instruction = f"""
        Simule o armazenamento de chunks no vector database:
        
        Chunks: {len(chunks.chunks)} chunks gerados
        Collection: {state.collection_names}
        User ID: {state.user_id}
        Document Scope: {state.document_scope}
        
        Retorne status de ingestion realÃ­stico.
        """
        
        storage_result = llm(instruction, IngestionResult,
                           chunks=chunks.chunks,
                           collection=state.collection_names,
                           user_id=state.user_id)
        
        ingestion_results[doc_info["id"]] = storage_result
    
    return state.copy(
        ingestion_status=ingestion_results,
        needs_ingestion=False,
        user_documents=[doc["id"] for doc in state.documents_to_ingest]
    )
```

### **4. Document Retrieval Node**

```python
# sample_agent/agents/tce_swarm/rag/nodes/document_retrieval.py

from ..utils import llm, mock_vector_search
from ..models.state import TCE_RAG_State
from ..models.responses import RetrievalResult

def document_retrieval_node(state: TCE_RAG_State) -> TCE_RAG_State:
    """
    Executa retrieval hÃ­brido nos chunks jÃ¡ armazenados
    """
    
    # Configurar filtros baseados no escopo
    filters = {
        "document_scope": state.document_scope
    }
    
    if state.document_scope == "user_specific":
        filters["user_id"] = state.user_id
    elif state.document_scope == "session_specific":
        filters["session_id"] = state.session_id
    
    # Busca em mÃºltiplas collections
    all_chunks = []
    
    for collection in state.collection_names:
        # Mock da busca semÃ¢ntica
        semantic_results = mock_vector_search(
            state.processed_query,
            collection,
            {**filters, "search_type": "semantic"}
        )
        
        # Mock da busca por keywords
        keyword_results = mock_vector_search(
            state.processed_query,
            collection,
            {**filters, "search_type": "keyword"}
        )
        
        # Combinar resultados
        instruction = f"""
        Combine resultados de busca semÃ¢ntica e keyword:
        
        Semantic Results: {len(semantic_results.chunks)} chunks
        Keyword Results: {len(keyword_results.chunks)} chunks
        
        Pesos: Semantic 0.7, Keyword 0.3
        
        Retorne top 20 chunks combinados sem duplicatas.
        """
        
        combined = llm(instruction, RetrievalResult,
                      semantic_results=semantic_results.chunks,
                      keyword_results=keyword_results.chunks,
                      query=state.processed_query)
        
        all_chunks.extend(combined.chunks)
    
    # DeduplicaÃ§Ã£o e ranking final
    instruction = f"""
    Deduplique e rankeie {len(all_chunks)} chunks por relevÃ¢ncia:
    
    Query: {state.processed_query}
    
    Retorne top 10 chunks Ãºnicos ordenados por relevÃ¢ncia.
    """
    
    final_result = llm(instruction, RetrievalResult,
                      all_chunks=all_chunks,
                      query=state.processed_query)
    
    return state.copy(
        retrieved_chunks=final_result.chunks,
        retrieval_time=final_result.processing_time,
        vector_db_queries=len(state.collection_names) * 2
    )
```

---

## ğŸ¯ **EstratÃ©gia de MigraÃ§Ã£o Mock â†’ Real**

### **1. SubstituiÃ§Ã£o Modular**

```python
# Estrutura atual (PoC)
from .utils import llm, mock_document_processing

def document_ingestion_node(state):
    parsing_result = mock_document_processing(file_path, doc_type)
    # ... resto do cÃ³digo

# Estrutura futura (ProduÃ§Ã£o)
from .processors.docling_processor import DoclingProcessor

def document_ingestion_node(state):
    processor = DoclingProcessor()
    parsing_result = processor.process_document(file_path, doc_type)
    # ... resto do cÃ³digo IDÃŠNTICO
```

### **2. Interface Consistente**

Todos os mocks retornam **exatamente a mesma estrutura** que as implementaÃ§Ãµes reais:

```python
# Mock e Real retornam DoclingProcessingResult
class DoclingProcessingResult(BaseModel):
    success: bool
    raw_markdown: str
    structured_content: TCEStructure
    metadata: Dict[str, Any]
    confidence: float
```

---

## ğŸ§ª **ValidaÃ§Ã£o e Testes**

### **1. Testes de IntegraÃ§Ã£o**

```python
# test_rag_pipeline.py

def test_full_pipeline():
    """Testa pipeline completo com mocks"""
    
    state = TCE_RAG_State(
        original_query="Qual Ã© o prazo para recurso em processos TCE-PA?",
        user_id="test_user",
        session_id="test_session"
    )
    
    # Executa pipeline completo
    result = tce_rag_subgraph.invoke(state)
    
    # ValidaÃ§Ãµes
    assert result.generated_response
    assert result.quality_score > 0.7
    assert len(result.citations) > 0
    assert result.processing_time < 10.0
```

### **2. Testes de Comportamento**

```python
def test_realistic_behavior():
    """Verifica se mocks geram comportamento realÃ­stico"""
    
    # Teste com diferentes tipos de documento
    for doc_type in ["legislation", "acordao", "resolucao"]:
        result = mock_document_processing(f"test_{doc_type}.pdf", doc_type)
        
        # Comportamento esperado por tipo
        if doc_type == "legislation":
            assert len(result.structured_content.articles) > 0
        elif doc_type == "acordao":
            assert "ACÃ“RDÃƒO" in result.structured_content.header
```

## ğŸ¯ **Vantagens da Abordagem**

### **âœ… BenefÃ­cios Imediatos**
- **ValidaÃ§Ã£o RÃ¡pida**: Pipeline completo em dias, nÃ£o semanas
- **Comportamento RealÃ­stico**: LLM gera respostas contextualmente apropriadas
- **Modularidade**: MigraÃ§Ã£o sem refatoraÃ§Ã£o de arquitetura
- **Teste Completo**: Fluxo end-to-end funcionando

### **âœ… BenefÃ­cios Futuros**
- **MigraÃ§Ã£o Suave**: SubstituiÃ§Ã£o gradual componente por componente
- **Risco Reduzido**: Arquitetura validada antes da implementaÃ§Ã£o real
- **Feedback Antecipado**: UsuÃ¡rios podem avaliar comportamento
- **DocumentaÃ§Ã£o Viva**: EspecificaÃ§Ãµes testadas e funcionais

---

## ğŸ”§ **Comandos de ExecuÃ§Ã£o**

### **Setup da PoC**
```bash
# Instalar dependÃªncias
uv sync

# Configurar ambiente
export USE_MOCKS=true
export OPENAI_API_KEY=your_key

# Executar testes
python -m pytest sample_agent/agents/tce_swarm/rag/tests/

# Demo completa
python sample_agent/agents/tce_swarm/demo.py --rag-poc
```

### **MigraÃ§Ã£o para ProduÃ§Ã£o**
```bash
# Desabilitar mocks
export USE_MOCKS=false

# Instalar dependÃªncias reais
uv add docling chonkie-ai chromadb

# Executar com implementaÃ§Ãµes reais
python sample_agent/agents/tce_swarm/demo.py --production
```

---

## ğŸ“‹ **Resumo Executivo**

### **EstratÃ©gia**
**PoC Inteligente** usando LLM structured output para simular comportamento realÃ­stico do pipeline RAG agentico, mantendo arquitetura modular para migraÃ§Ã£o suave.

### **EntregÃ¡veis**
1. **Pipeline RAG Completo** com 8 nÃ³s funcionais
2. **Respostas RealÃ­sticas** via LLM bem instruÃ­das
3. **Arquitetura Modular** para migraÃ§Ã£o gradual
4. **ValidaÃ§Ã£o End-to-End** com mÃ©tricas e observabilidade

### **Timeline**
**11 dias** para PoC completa funcional, pronta para avaliaÃ§Ã£o e feedback.

### **PrÃ³ximos Passos**
1. **AprovaÃ§Ã£o** do plano de implementaÃ§Ã£o
2. **InÃ­cio da Fase 1** - Setup da estrutura base
3. **ImplementaÃ§Ã£o iterativa** com validaÃ§Ã£o contÃ­nua
4. **Demo e avaliaÃ§Ã£o** com stakeholders

**Status**: ğŸ“‹ **Plano aprovado - Pronto para implementaÃ§Ã£o** 