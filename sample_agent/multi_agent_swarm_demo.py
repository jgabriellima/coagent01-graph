# Multi-Agent Swarm System Demo
# Este script demonstra um sistema multi-agente usando LangGraph com padr√£o Swarm

from typing_extensions import Literal, TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langchain.tools import tool
from langgraph.types import Command
from langgraph_supervisor import create_supervisor

from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import (
    AgentState,
    AgentStateWithStructuredResponse,
)
from langchain_groq import ChatGroq
from langchain.chat_models import init_chat_model
from typing import Annotated
from langgraph.types import Command, interrupt
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool, InjectedToolCallId, BaseTool
import os
from langgraph.graph import StateGraph, MessagesState
from langgraph.constants import START, END
from pydantic import BaseModel
import operator
from langchain_core.messages import BaseMessage
from langgraph.prebuilt import create_react_agent
from langgraph_swarm import (
    create_handoff_tool,
    create_swarm,
    SwarmState,
    add_active_agent_router,
)

# =============================================================================
# 1. CONFIGURA√á√ÉO INICIAL
# =============================================================================

# Configura√ß√£o dos modelos
model = init_chat_model("openai:gpt-4o-mini", temperature=0)
model_groq = model  # Para fallback se necess√°rio

print("‚úÖ Importa√ß√µes e modelos configurados")

# =============================================================================
# 2. DEFINI√á√ÉO DE TOOLS ESPECIALIZADAS
# =============================================================================

def get_weather(location: str, tool_call_id: Annotated[str, InjectedToolCallId]):
    """
    Get the weather for a given location.
    """
    print(f"üå§Ô∏è Getting weather for {location}")

    return Command(
        update={
            "location": location,
            "temperature": "70 degrees",
            "date": "2025-01-01",
            "time": "12:00:00",
            "tool_call_id": tool_call_id,
            "messages": [
                ToolMessage(
                    f"The weather for {location} is 70 degrees.",
                    tool_call_id=tool_call_id,
                )
            ],
        }
    )

def calculate_math(expression: str, tool_call_id: Annotated[str, InjectedToolCallId]):
    """
    Calculate a simple math expression.
    Example: "2 + 3" or "10 * 5"
    """
    print(f"üßÆ Calculating math for {expression}")
    try:
        if "+" in expression:
            parts = expression.split("+")
            result = sum(float(part.strip()) for part in parts)
        elif "*" in expression:
            parts = expression.split("*")
            result = 1
            for part in parts:
                result *= float(part.strip())
        elif "-" in expression:
            parts = expression.split("-")
            result = float(parts[0].strip()) - float(parts[1].strip())
        elif "/" in expression:
            parts = expression.split("/")
            result = float(parts[0].strip()) / float(parts[1].strip())
        else:
            result = float(expression.strip())

        return Command(
            update={
                "math_expression": expression,
                "math_result": result,
                "messages": [
                    ToolMessage(
                        f"The result of {expression} is {result}",
                        tool_call_id=tool_call_id,
                    )
                ],
            }
        )
    except:
        return f"Could not calculate {expression}. Please use format like '2 + 3' or '10 * 5'"

def ask_user(question_to_user: str, tool_call_id: Annotated[str, InjectedToolCallId]):
    """This tool is used to ask the user any question. Its important always ask for things to make sure you're using the right information."""
    user_response = interrupt(
        {
            "type": "question",
            "question": question_to_user,
            "tool_call_id": tool_call_id,
        }
    )
    print(f"üë§ User response: {user_response}")

    return f"The user answered with: {user_response.values()}"

print("üîß Tools configuradas: get_weather, calculate_math, ask_user")

# =============================================================================
# 3. ESTADOS DOS AGENTES E CONFIGURA√á√ÉO DO WORKFLOW
# =============================================================================

# Estados dos agentes
class FullState(AgentState):
    temperature: float
    location: str
    weather: str
    math_expression: str
    math_result: str

class FullSwarmState(SwarmState, FullState):
    temperature: float
    location: str
    weather: str
    math_expression: str
    math_result: str

# Fun√ß√£o de compila√ß√£o com MemoryCheckpointer
def compile_workflow(workflow: StateGraph):
    """Compila o workflow com MemoryCheckpointer para inspe√ß√£o de estado"""
    is_langgraph_api = (
        os.environ.get("LANGGRAPH_API", "false").lower() == "true"
        or os.environ.get("LANGGRAPH_API_DIR") is not None
    )

    if is_langgraph_api:
        return workflow.compile()
    else:
        from langgraph.checkpoint.memory import MemorySaver

        memory = MemorySaver()
        return workflow.compile(checkpointer=memory)

print("üìã Estados definidos e fun√ß√£o de compila√ß√£o configurada")

# =============================================================================
# 4. CRIA√á√ÉO DOS AGENTES ESPECIALIZADOS
# =============================================================================

def create_main_agent():
    """Cria o Main Agent - Coordenador Principal"""
    main_agent_model = init_chat_model("openai:gpt-4o-mini", temperature=0)
    main_agent_tools = [
        ask_user,
        create_handoff_tool(
            agent_name="Alice",
            description="Transfer to Alice, she can help with any math",
        ),
        create_handoff_tool(
            agent_name="Bob", description="Transfer to Bob, he can help with weather"
        ),
    ]
    main_agent_model_bind_tools = main_agent_model.bind_tools(
        main_agent_tools,
        parallel_tool_calls=False,
    )

    main_agent = create_react_agent(
        main_agent_model_bind_tools,
        main_agent_tools,
        prompt="""You are the Main Coordination Agent responsible for task orchestration and completion.

CORE RESPONSIBILITIES:
1. Analyze incoming tasks and develop a strategic execution plan
2. Gather necessary information from users when requirements are unclear
3. Delegate specialized tasks to appropriate expert agents
4. Coordinate between agents to ensure seamless task completion

WORKFLOW PROCESS:
1. ANALYZE: Break down the user's request and identify required expertise
2. PLAN: Structure a clear strategy outlining steps and agent assignments
3. GATHER: Use `ask_user` tool to collect missing information before proceeding
4. DELEGATE: Hand off specific, well-defined subtasks to specialized agents
5. COORDINATE: Monitor progress and facilitate inter-agent communication

HANDOFF PROTOCOL:
- Always provide clear, specific instructions when transferring tasks
- Include relevant context and expected deliverables
- Ensure each agent receives the exact information needed for their specialization

Remember: Strategic planning before action ensures optimal task completion.""",
        name="main_agent",
        state_schema=FullState,
    )
    
    print("üéØ Main Agent (Coordenador) criado")
    return main_agent

def create_alice_agent():
    """Cria Alice - Especialista em Matem√°tica"""
    alice_model = init_chat_model("openai:gpt-4o-mini", temperature=0)
    alice_tools = [
        calculate_math,
        create_handoff_tool(
            agent_name="Bob", description="Transfer to Bob, he can help with weather"
        ),
        create_handoff_tool(
            agent_name="main_agent",
            description="Use this tool to send or ask the user for information to complete the task.",
        ),
    ]
    alice_model_bind_tools = alice_model.bind_tools(
        alice_tools,
        parallel_tool_calls=False,
    )

    alice = create_react_agent(
        alice_model_bind_tools,
        alice_tools,
        prompt="You are Alice, an calculator expert. you are given a math expression and you need to calculate the result. If you need to ask the user for information, handoff to the main_agent.",
        name="Alice",
        state_schema=FullState
    )
    
    print("üßÆ Alice (Especialista em Matem√°tica) criada")
    return alice

def create_bob_agent():
    """Cria Bob - Especialista em Clima (Pirata)"""
    bob_model = init_chat_model("openai:gpt-4o-mini", temperature=0)
    bob_tools = [
        ask_user,
        get_weather,
        create_handoff_tool(
            agent_name="Alice",
            description="Transfer to Alice, she can help with any math or any calculation",
        ),
        create_handoff_tool(
            agent_name="main_agent",
            description="Use this tool to send or ask the user for information to complete the task.",
        ),
    ]
    bob_model_bind_tools = bob_model.bind_tools(
        bob_tools,
        parallel_tool_calls=False,
    )

    bob = create_react_agent(
        bob_model_bind_tools,
        bob_tools,
        prompt="You are Bob, you speak like a pirate and you are a weather specialist. You are given a location and you need to return the weather for that location using the `get_weather` tool. If you need any user information, handoff back to the main_agent. To get the number that the user is thinking handoff back to the main_agent.",
        name="Bob",
        state_schema=FullState
    )
    
    print("üè¥‚Äç‚ò†Ô∏è Bob (Especialista em Clima - Pirata) criado")
    return bob

# =============================================================================
# 5. CONSTRU√á√ÉO DO WORKFLOW MULTI-AGENTE
# =============================================================================

def create_multi_agent_system():
    """Cria o sistema multi-agente completo"""
    # Criar agentes
    main_agent = create_main_agent()
    alice = create_alice_agent()
    bob = create_bob_agent()
    
    # Cria√ß√£o do workflow
    workflow = (
        StateGraph(FullSwarmState)
        .add_node(
            main_agent,
            destinations=(
                "Alice",
                "Bob",
            ),
        )
        .add_node(alice, destinations=("main_agent", "Bob"))
        .add_node(bob, destinations=("main_agent", "Alice"))
    )

    # Adiciona o roteador para rastrear agente ativo
    workflow = add_active_agent_router(
        builder=workflow,
        route_to=["main_agent", "Alice", "Bob"],
        default_active_agent="main_agent",
    )

    # Compila o grafo com MemoryCheckpointer
    graph = compile_workflow(workflow)

    print("üöÄ Workflow multi-agente criado e compilado com MemoryCheckpointer")
    print(f"üìä Nodes no grafo: {list(graph.get_graph().nodes.keys())}")
    
    return graph

# =============================================================================
# 6. EXEMPLO DE EXECU√á√ÉO: CLIMA + C√ÅLCULO
# =============================================================================

def run_campeche_example(graph):
    """
    Executa o exemplo: "Qual a temperatura atual no Campeche? 
    Agora pegue essa temperatura e multiplique pelo numero que eu estou pensando e me retorne o final."
    """
    # Configura√ß√£o do thread para rastreamento
    thread_config = {"configurable": {"thread_id": "demo-campeche-calc"}}

    # Input inicial
    initial_input = {
        "messages": [
            HumanMessage(
                content="Qual a temperatura atual no Campeche? Agora pegue essa temperatura e multiplique pelo numero que eu estou pensando e me retorne o final."
            )
        ]
    }

    print("üé¨ Iniciando execu√ß√£o do exemplo...")
    print(f"üí¨ Input: {initial_input['messages'][0].content}")
    print("\n" + "="*60)
    
    # Execu√ß√£o step-by-step para observar o fluxo
    step_count = 0
    current_state = initial_input

    try:
        for step in graph.stream(current_state, thread_config, stream_mode="values"):
            step_count += 1
            print(f"\nüö∂‚Äç‚ôÇÔ∏è STEP {step_count}:")
            print(f"üéØ Active Agent: {step.get('active_agent', 'Unknown')}")
            
            # Estado atual detalhado
            print(f"üìç Location: {step.get('location', 'N/A')}")
            print(f"üå°Ô∏è Temperature: {step.get('temperature', 'N/A')}")
            print(f"üßÆ Math Expression: {step.get('math_expression', 'N/A')}")
            print(f"üî¢ Math Result: {step.get('math_result', 'N/A')}")
            
            # √öltima mensagem
            if 'messages' in step and step['messages']:
                last_message = step['messages'][-1]
                print(f"üí¨ Message Type: {type(last_message).__name__}")
                
                if hasattr(last_message, 'content') and last_message.content:
                    content = str(last_message.content)
                    if len(content) > 200:
                        content = content[:200] + "..."
                    print(f"üí¨ Content: {content}")
                
                if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                    for tool_call in last_message.tool_calls:
                        print(f"üîß Tool Call: {tool_call.get('name', 'Unknown')}")
                        print(f"üìã Args: {tool_call.get('args', {})}")
            
            print("‚îÄ" * 50)
            
            # Verifica se precisa de interrup√ß√£o (pergunta ao usu√°rio)
            current_state = step
            
            # Limita execu√ß√£o para evitar loop infinito
            if step_count > 10:
                print("‚ö†Ô∏è Limitando execu√ß√£o em 10 steps para seguran√ßa")
                break

    except Exception as e:
        print(f"‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()

    print(f"\n‚úÖ Execu√ß√£o conclu√≠da ap√≥s {step_count} steps")
    
    return thread_config

# =============================================================================
# 7. INSPE√á√ÉO DO ESTADO DO CHECKPOINTER
# =============================================================================

def inspect_checkpointer_state(graph, thread_config):
    """Inspeciona o estado salvo no checkpointer"""
    try:
        saved_state = graph.get_state(thread_config)
        print("üíæ ESTADO SALVO NO CHECKPOINTER:")
        print("‚îÄ" * 40)
        
        if saved_state and saved_state.values:
            state_values = saved_state.values
            
            print(f"üéØ Active Agent: {state_values.get('active_agent', 'N/A')}")
            print(f"üìç Location: {state_values.get('location', 'N/A')}")
            print(f"üå°Ô∏è Temperature: {state_values.get('temperature', 'N/A')}")
            print(f"üßÆ Math Expression: {state_values.get('math_expression', 'N/A')}")
            print(f"üî¢ Math Result: {state_values.get('math_result', 'N/A')}")
            print(f"üìÖ Date: {state_values.get('date', 'N/A')}")
            print(f"‚è∞ Time: {state_values.get('time', 'N/A')}")
            
            # Contagem de mensagens
            if 'messages' in state_values:
                print(f"üí¨ Total Messages: {len(state_values['messages'])}")
                
                # √öltimas 3 mensagens
                print("\nüìù √öLTIMAS MENSAGENS:")
                for i, msg in enumerate(state_values['messages'][-3:], 1):
                    msg_type = type(msg).__name__
                    content = getattr(msg, 'content', 'No content')
                    if len(str(content)) > 150:
                        content = str(content)[:150] + "..."
                    print(f"  {i}. {msg_type}: {content}")
        
        # Metadados do checkpoint
        if saved_state and saved_state.metadata:
            print(f"\nüîñ Checkpoint Metadata:")
            print(f"   Step: {saved_state.metadata.get('step', 'N/A')}")
            print(f"   Source: {saved_state.metadata.get('source', 'N/A')}")
            
    except Exception as e:
        print(f"‚ùå Erro ao acessar estado do checkpointer: {e}")

    print("\n" + "="*60)

# =============================================================================
# 8. SIMULA√á√ÉO DE RESPOSTA DO USU√ÅRIO
# =============================================================================

def continue_with_user_input(graph, thread_config, user_input, max_steps=5):
    """Continua a execu√ß√£o com input do usu√°rio"""
    print(f"üé≠ Continuando com resposta do usu√°rio: '{user_input}'")
    
    try:
        # Continua a partir do estado atual
        step_count = 0
        for step in graph.stream({"user_input": str(user_input)}, thread_config, stream_mode="values"):
            step_count += 1
            print(f"\nüö∂‚Äç‚ôÇÔ∏è CONTINUATION STEP {step_count}:")
            print(f"üéØ Active Agent: {step.get('active_agent', 'Unknown')}")
            print(f"üî¢ Math Result: {step.get('math_result', 'N/A')}")
            
            if 'messages' in step and step['messages']:
                last_message = step['messages'][-1]
                if hasattr(last_message, 'content'):
                    content = str(last_message.content)
                    if len(content) > 200:
                        content = content[:200] + "..."
                    print(f"üí¨ Content: {content}")
            
            if step_count >= max_steps:
                break
                
    except Exception as e:
        print(f"‚ö†Ô∏è Erro na continua√ß√£o: {e}")

# =============================================================================
# 9. AN√ÅLISE FINAL DO ESTADO
# =============================================================================

def analyze_final_state(graph, thread_config):
    """An√°lise final do estado"""
    # Estado final completo
    final_state = graph.get_state(thread_config)

    print("üìä AN√ÅLISE FINAL DO ESTADO:")
    print("‚ïê" * 50)

    if final_state and final_state.values:
        values = final_state.values
        
        print(f"üèÅ Estado Final:")
        print(f"   üéØ Agente Ativo: {values.get('active_agent', 'N/A')}")
        print(f"   üìç Localiza√ß√£o: {values.get('location', 'N/A')}")
        print(f"   üå°Ô∏è Temperatura: {values.get('temperature', 'N/A')}")
        print(f"   üßÆ Express√£o Matem√°tica: {values.get('math_expression', 'N/A')}")
        print(f"   üî¢ Resultado do C√°lculo: {values.get('math_result', 'N/A')}")
        
        print(f"\nüìà Estat√≠sticas:")
        print(f"   üí¨ Total de Mensagens: {len(values.get('messages', []))}")
        
        # Fluxo de agentes
        agent_flow = []
        for msg in values.get('messages', []):
            if hasattr(msg, 'name') and msg.name:
                agent_flow.append(msg.name)
        
        if agent_flow:
            print(f"   üîÑ Fluxo de Agentes: {' ‚Üí '.join(set(agent_flow))}")
        
        print(f"\nüéØ RESULTADO ESPERADO:")
        if values.get('temperature') and values.get('math_result'):
            temp = values.get('temperature', '').replace(' degrees', '')
            try:
                temp_num = float(temp)
                result = values.get('math_result', 0)
                print(f"   üå°Ô∏è Temperatura do Campeche: {temp}¬∞")
                print(f"   üî¢ N√∫mero pensado: {result/temp_num if temp_num != 0 else 'N/A'}")
                print(f"   ‚úÖ Resultado Final: {temp}¬∞ √ó n√∫mero = {result}")
            except:
                print(f"   ‚ö†Ô∏è N√£o foi poss√≠vel calcular o resultado final")
        else:
            print(f"   ‚ö†Ô∏è Execu√ß√£o incompleta - execute as fun√ß√µes acima primeiro")

    print("\n" + "‚ïê" * 50)
    print("üéâ Demonstra√ß√£o do Sistema Multi-Agente Conclu√≠da!")

# =============================================================================
# 10. UTILIT√ÅRIOS PARA DEBUGGING
# =============================================================================

def reset_conversation(thread_id="demo-reset"):
    """Reset conversation state for new testing"""
    new_config = {"configurable": {"thread_id": thread_id}}
    print(f"üîÑ Conversa√ß√£o resetada com thread_id: {thread_id}")
    return new_config

def inspect_state_details(graph, config):
    """Inspeciona detalhes do estado atual"""
    try:
        state = graph.get_state(config)
        if state and state.values:
            print("üîç DETALHES DO ESTADO:")
            for key, value in state.values.items():
                if key != 'messages':
                    print(f"   {key}: {value}")
            
            if 'messages' in state.values:
                print(f"\nüì® Mensagens ({len(state.values['messages'])}):")
                for i, msg in enumerate(state.values['messages'][-5:], 1):
                    print(f"   {i}. {type(msg).__name__}: {str(msg)[:100]}...")
        else:
            print("‚ö†Ô∏è Nenhum estado encontrado")
    except Exception as e:
        print(f"‚ùå Erro ao inspecionar estado: {e}")

print("üõ†Ô∏è Utilit√°rios de debugging configurados")

# =============================================================================
# 11. FUN√á√ÉO PRINCIPAL PARA EXECUTAR TUDO
# =============================================================================

def main():
    """Fun√ß√£o principal que executa toda a demonstra√ß√£o"""
    print("üöÄ INICIANDO DEMONSTRA√á√ÉO DO SISTEMA MULTI-AGENTE")
    print("‚ïê" * 60)
    
    # 1. Criar sistema multi-agente
    graph = create_multi_agent_system()
    
    # 2. Executar exemplo do Campeche
    thread_config = run_campeche_example(graph)
    
    # 3. Inspecionar estado do checkpointer
    inspect_checkpointer_state(graph, thread_config)
    
    # 4. Simular resposta do usu√°rio (n√∫mero 3)
    user_number = 3
    print(f"\nüé≠ Simulando resposta do usu√°rio: '{user_number}'")
    continue_with_user_input(graph, thread_config, user_number)
    
    # 5. An√°lise final
    analyze_final_state(graph, thread_config)
    
    print("\nüí° FUN√á√ïES DISPON√çVEIS PARA USO POSTERIOR:")
    print("   - reset_conversation(thread_id)")
    print("   - inspect_state_details(graph, config)")
    print("   - continue_with_user_input(graph, thread_config, user_input)")
    
    return graph, thread_config

if __name__ == "__main__":
    # Executar demonstra√ß√£o completa
    graph, thread_config = main() 