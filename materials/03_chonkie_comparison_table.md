# Chonkie.ai - Advanced Text Chunking for RAG Applications

`by Jo√£o Gabriel Lima`

## Chunkers Comparison Table

A tabela abaixo detalha as principais diferen√ßas, casos de uso e funcionamento de cada chunker dispon√≠vel no Chonkie.ai:

| Chunker | Estrat√©gia | Caso de Uso Ideal | Performance | Complexidade | Requer Modelo |
|---------|------------|-------------------|-------------|--------------|---------------|
| **TokenChunker** | Divis√£o por tokens fixos | APIs com limites de tokens, controle preciso | Muito Alta | Baixa | Tokenizer |
| **SentenceChunker** | Divis√£o por limites de senten√ßa | Documentos bem estruturados, textos narrativos | Alta | Baixa | N√£o |
| **RecursiveChunker** | Divis√£o hier√°rquica com regras customiz√°veis | Documentos hier√°rquicos, papers acad√™micos | M√©dia-Alta | M√©dia | N√£o |
| **SemanticChunker** | Agrupamento por similaridade sem√¢ntica | Documentos longos, conte√∫do heterog√™neo | M√©dia | Alta | Embedding Model |
| **SDPMChunker** | Semantic Double-Pass Merge | Documentos complexos, alta precis√£o sem√¢ntica | M√©dia-Baixa | Muito Alta | Embedding Model |
| **LateChunker** | Embedding primeiro, chunk depois | RAG avan√ßado, preserva√ß√£o de contexto | Baixa | Muito Alta | Embedding Model |
| **NeuralChunker** | Chunking baseado em redes neurais | Documentos n√£o estruturados, ML avan√ßado | Baixa | Muito Alta | Neural Model |
| **SlumberChunker** | Chunking otimizado para embeddings | Otimiza√ß√£o para embedding models | M√©dia | Alta | Embedding Model |
| **CodeChunker** | Chunking espec√≠fico para c√≥digo fonte | Reposit√≥rios de c√≥digo, documenta√ß√£o t√©cnica | Alta | M√©dia | N√£o |

## üîç **Detalhamento das Estrat√©gias**

### **TokenChunker** üöÄ
- **Como funciona**: Divide texto em chunks de tamanho fixo baseado em contagem de tokens
- **Vantagem**: Controle preciso para limites de API, processamento muito r√°pido
- **Ideal para**: OpenAI API, Claude API, modelos com limites r√≠gidos de contexto

### **SentenceChunker** üìù  
- **Como funciona**: Agrupa senten√ßas em chunks respeitando limites sem√¢nticos
- **Vantagem**: Preserva integridade sem√¢ntica, f√°cil de implementar
- **Ideal para**: Textos narrativos, documentos educacionais, artigos de blog

### **RecursiveChunker** üå≥
- **Como funciona**: Aplica regras hier√°rquicas (headers ‚Üí par√°grafos ‚Üí senten√ßas)
- **Vantagem**: Respeita estrutura do documento, configur√°vel
- **Ideal para**: Papers acad√™micos, documenta√ß√£o t√©cnica, relat√≥rios estruturados

### **SemanticChunker** üß†
- **Como funciona**: Usa embeddings para agrupar conte√∫do semanticamente similar
- **Vantagem**: Chunks tematicamente coerentes, melhor para recupera√ß√£o
- **Ideal para**: Documentos longos, conte√∫do multi-t√≥pico, knowledge bases

### **LateChunker** ‚ö°
- **Como funciona**: Processa documento inteiro primeiro, depois chunking com contexto global
- **Vantagem**: Preserva contexto m√°ximo, estado da arte para RAG
- **Ideal para**: RAG de alta qualidade, documentos complexos

### **SDPMChunker** üîÑ
- **Como funciona**: Semantic Double-Pass Merge - duas passadas para otimizar sem√¢ntica
- **Vantagem**: M√°xima precis√£o sem√¢ntica, reduz perda de contexto
- **Ideal para**: Documentos cient√≠ficos complexos, an√°lise legal, pesquisa m√©dica

### **NeuralChunker** ü§ñ
- **Como funciona**: Redes neurais treinadas para identificar pontos ideais de divis√£o
- **Vantagem**: Aprende padr√µes complexos, adapt√°vel a diferentes dom√≠nios
- **Ideal para**: Textos n√£o estruturados, linguagem natural complexa

### **SlumberChunker** üò¥
- **Como funciona**: Chunking otimizado especificamente para modelos de embedding
- **Vantagem**: Maximiza qualidade dos embeddings resultantes
- **Ideal para**: Sistemas de busca sem√¢ntica, recomenda√ß√£o de conte√∫do

### **CodeChunker** üíª
- **Como funciona**: Usa AST (Abstract Syntax Tree) para chunking inteligente de c√≥digo
- **Vantagem**: Preserva estrutura sint√°tica, respeita fun√ß√µes e classes
- **Ideal para**: Documenta√ß√£o de c√≥digo, an√°lise de reposit√≥rios, AI coding assistants

## ‚öñÔ∏è **Guia de Sele√ß√£o R√°pida**

| Prioridade | Escolha | Justificativa |
|------------|---------|---------------|
| **Velocidade** | TokenChunker ‚Üí SentenceChunker ‚Üí CodeChunker | Performance m√°xima |
| **Qualidade RAG** | LateChunker ‚Üí SDPMChunker ‚Üí SemanticChunker | Contexto preservado |
| **Simplicidade** | SentenceChunker ‚Üí TokenChunker ‚Üí RecursiveChunker | F√°cil implementa√ß√£o |
| **Flexibilidade** | RecursiveChunker ‚Üí SemanticChunker ‚Üí NeuralChunker | Configurabilidade |

## Installation

```bash
# Installation - Base package
uv add chonkie

# Installation - Full features
uv add "chonkie[all]"

# Additional dependencies for comprehensive testing
uv add tiktoken sentence-transformers transformers torch numpy pandas matplotlib seaborn
```

## Example Usage

```python
# Basic TokenChunker example
from chonkie import TokenChunker

chunker = TokenChunker(chunk_size=512)
chunks = chunker("Your text here...")

for chunk in chunks:
    print(f"Chunk: {chunk.text}")
    print(f"Tokens: {chunk.token_count}")
```

```python
# SentenceChunker example
from chonkie import SentenceChunker

chunker = SentenceChunker(sentences_per_chunk=3)
chunks = chunker("Your text here...")

for chunk in chunks:
    print(f"Chunk: {chunk.text}")
```

```python
# RecursiveChunker example
from chonkie import RecursiveChunker

chunker = RecursiveChunker(chunk_size=1024)
chunks = chunker("Your text here...")

for chunk in chunks:
    print(f"Chunk: {chunk.text}")
```

## References

- **Official Website**: [chonkie.ai](https://chonkie.ai)
- **Documentation**: [docs.chonkie.ai](https://docs.chonkie.ai)
- **GitHub Repository**: [github.com/chonkie-ai/chonkie](https://github.com/chonkie-ai/chonkie)
- **PyPI Package**: [pypi.org/project/chonkie](https://pypi.org/project/chonkie)

---

**Created by:** Jo√£o Gabriel Lima  
**Date:** January 2025  
**ü¶õ Ready to CHONK!** ‚ú® 